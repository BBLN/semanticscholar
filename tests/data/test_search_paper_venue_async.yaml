interactions:
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - api.semanticscholar.org
      user-agent:
      - python-httpx/0.24.1
    method: GET
    uri: https://api.semanticscholar.org/graph/v1/paper/search?query=turing&venue=ArXiv&fields=abstract,authors,citationCount,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100
  response:
    content: '{"total": 775, "offset": 0, "next": 100, "data": [{"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19",
      "externalIds": {"DBLP": "journals/corr/abs-2201-11990", "ArXiv": "2201.11990",
      "CorpusId": 246411325}, "corpusId": 246411325, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/7cbc2a7843411a1768ab762930707af0a3c33a19",
      "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A
      Large-Scale Generative Language Model", "abstract": "Pretrained general-purpose
      language models can achieve state-of-the-art accuracies in various natural language
      processing domains by adapting to downstream tasks via zero-shot, few-shot and
      fine-tuning techniques. Because of their success, the size of these models has
      increased rapidly, requiring high-performance hardware, software, and algorithmic
      techniques to enable training such large models. As the result of a joint effort
      between Microsoft and NVIDIA, we present details on the training of the largest
      monolithic transformer based language model, Megatron-Turing NLG 530B (MT-NLG),
      with 530 billion parameters. In this paper, we first focus on the infrastructure
      as well as the 3D parallelism methodology used to train this model using DeepSpeed
      and Megatron. Next, we detail the training process, the design of our training
      corpus, and our data curation techniques, which we believe is a key ingredient
      to the success of the model. Finally, we discuss various evaluation results,
      as well as other interesting observations and new properties exhibited by MT-NLG.
      We demonstrate that MT-NLG achieves superior zero-, one-, and few-shot learning
      accuracies on several NLP benchmarks and establishes new state-of-the-art results.
      We believe that our contributions will help further the development of large-scale
      training infrastructures, large-scale language models, and natural language
      generations.", "venue": "arXiv.org", "year": 2022, "referenceCount": 77, "citationCount":
      389, "influentialCitationCount": 29, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2022-01-28", "journal": {"name": "ArXiv", "volume": "abs/2201.11990"}, "authors":
      [{"authorId": "2110486618", "name": "Shaden Smith"}, {"authorId": "66870756",
      "name": "M. Patwary"}, {"authorId": "2172095", "name": "Brandon Norick"}, {"authorId":
      "3081566", "name": "P. LeGresley"}, {"authorId": "32817044", "name": "Samyam
      Rajbhandari"}, {"authorId": "48991386", "name": "J. Casper"}, {"authorId": "49293070",
      "name": "Zhun Liu"}, {"authorId": "9358910", "name": "Shrimai Prabhumoye"},
      {"authorId": "30647302", "name": "George Zerveas"}, {"authorId": "3111334",
      "name": "V. Korthikanti"}, {"authorId": "2151686157", "name": "Elton Zhang"},
      {"authorId": "48422824", "name": "Rewon Child"}, {"authorId": "3394222", "name":
      "Reza Yazdani Aminabadi"}, {"authorId": "2745589", "name": "J. Bernauer"}, {"authorId":
      "50706785", "name": "Xia Song"}, {"authorId": "1911755", "name": "M. Shoeybi"},
      {"authorId": "2145020341", "name": "Yuxiong He"}, {"authorId": "122523478",
      "name": "Michael Houston"}, {"authorId": "40070335", "name": "Saurabh Tiwary"},
      {"authorId": "2301680", "name": "Bryan Catanzaro"}]}, {"paperId": "c3823aacea60bc1f2cabb9283144690a3d015db5",
      "externalIds": {"DBLP": "journals/corr/GravesWD14", "ArXiv": "1410.5401", "MAG":
      "2950527759", "CorpusId": 15299054}, "corpusId": 15299054, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/c3823aacea60bc1f2cabb9283144690a3d015db5",
      "title": "Neural Turing Machines", "abstract": "We extend the capabilities of
      neural networks by coupling them to external memory resources, which they can
      interact with by attentional processes. The combined system is analogous to
      a Turing Machine or Von Neumann architecture but is differentiable end-toend,
      allowing it to be efficiently trained with gradient descent. Preliminary results
      demonstrate that Neural Turing Machines can infer simple algorithms such as
      copying, sorting, and associative recall from input and output examples.", "venue":
      "arXiv.org", "year": 2014, "referenceCount": 42, "citationCount": 1987, "influentialCitationCount":
      228, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2014-10-20", "journal": {"name": "ArXiv",
      "volume": "abs/1410.5401"}, "authors": [{"authorId": "1753223", "name": "Alex
      Graves"}, {"authorId": "89504302", "name": "Greg Wayne"}, {"authorId": "1841008",
      "name": "Ivo Danihelka"}]}, {"paperId": "836e7a4e2e290910d967e904b0930ddb104071a5",
      "externalIds": {"DBLP": "journals/corr/abs-2208-06279", "ArXiv": "2208.06279",
      "DOI": "10.48550/arXiv.2208.06279", "CorpusId": 251554593}, "corpusId": 251554593,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/836e7a4e2e290910d967e904b0930ddb104071a5",
      "title": "Developmental Network Two, Its Optimality, and Emergent Turing Machines",
      "abstract": "OF THE DISCLOSURE This invention includes a new type of neural
      network that is able to automatically and incrementally generate an internal
      hierarchy without a need to handcraft a static hierarchy of network areas and
      a static number of levels and the static number of neurons in each network area
      or level. This capability is achieved by enabling each neuron to have its own
      dynamic inhibitory zone using neuron-specific inhibitory connections.", "venue":
      "arXiv.org", "year": 2022, "referenceCount": 48, "citationCount": 10, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2022-08-04", "journal": {"name": "ArXiv",
      "volume": "abs/2208.06279"}, "authors": [{"authorId": "145926447", "name": "J.
      Weng"}, {"authorId": "2010802", "name": "Zejia Zheng"}, {"authorId": "2108404228",
      "name": "Xiang Wu"}]}, {"paperId": "58023c10496e238e24dc674761536ac0e4a8580b",
      "externalIds": {"ArXiv": "2201.09034", "DBLP": "journals/corr/abs-2201-09034",
      "CorpusId": 246240359}, "corpusId": 246240359, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/58023c10496e238e24dc674761536ac0e4a8580b",
      "title": "Strong Sleptsov Net is Turing-Complete", "abstract": "It is known
      that a Sleptsov net, with multiple firing a transition at a step, runs exponentially
      faster than a Petri net opening prospects for its application as a graphical
      language of concurrent programming. We provide classification of place-transition
      nets based on firability rules considering general definitions and their strong
      and weak variants. We introduce and study a strong Sleptsov net, where a transition
      with the maximal firing multiplicity fires at a step, and prove that it is Turing-complete.
      We follow the proof pattern of Peterson applied to prove that an inhibitor Petri
      net is Turing-complete simulating a Shepherdson and Sturgis register machine.
      The central construct of our proof is a strong Sleptsov net that checks whether
      a register value (place marking) equals zero.", "venue": "arXiv.org", "year":
      2022, "referenceCount": 47, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2022-01-22", "journal": {"name": "ArXiv",
      "volume": "abs/2201.09034"}, "authors": [{"authorId": "34716848", "name": "D.
      Zaitsev"}]}, {"paperId": "2a7e86f6af062445196dbc505d6422637e0d1fbd", "externalIds":
      {"ArXiv": "2201.04678", "DBLP": "journals/corr/abs-2201-04678", "CorpusId":
      245906284}, "corpusId": 245906284, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/2a7e86f6af062445196dbc505d6422637e0d1fbd",
      "title": "Polynomial Turing Compressions for Some Graph Problems Parameterized
      by Modular-Width", "abstract": "In this paper we investigate the parameterized
      complexity for NP-hard graph problems parameterized by a structural parameter
      modular-width. We develop a recipe that is able to simplify the process of obtaining
      polynomial Turing compressions for a class of graph problems parameterized by
      modular-width. By using the recipe, we demonstrate that several problems, which
      include chromatic number, independent set , hamiltonian cycle , etc. have polynomial
      Turing compressions parameterized by modular-width. In addition, under the assumption
      that P 6 = NP, we provide tight kernels for a few problems such as steiner tree
      parameterized by modular-width. As a byproduct of the result of the tight kernels,
      new parameterized algorithms for these problems are obtained.", "venue": "arXiv.org",
      "year": 2022, "referenceCount": 37, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2022-01-12", "journal": {"name": "ArXiv", "volume": "abs/2201.04678"}, "authors":
      [{"authorId": "49756279", "name": "Weidong Luo"}]}, {"paperId": "7849726f7176d93b770221f1d9e76129d95af6e2",
      "externalIds": {"ArXiv": "2204.00563", "DBLP": "journals/corr/abs-2204-00563",
      "DOI": "10.48550/arXiv.2204.00563", "CorpusId": 247922712}, "corpusId": 247922712,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/7849726f7176d93b770221f1d9e76129d95af6e2",
      "title": "Arithmetic logical Irreversibility and the Turing''s Halt Problem",
      "abstract": "The Turing machine halting problem can be explained by several
      factors, including arithmetic logic irreversibility and memory erasure, which
      contribute to computational uncertainty due to information loss during computation.
      Essentially, this means that an algorithm can only preserve information about
      an input, rather than generate new information. This uncertainty arises from
      characteristics such as arithmetic logical irreversibility, Landauer''s principle,
      and memory erasure, which ultimately lead to a loss of information and an increase
      in entropy. To measure this uncertainty and loss of information, the concept
      of arithmetic logical entropy can be used. The Turing machine and its equivalent,
      general recursive functions can be understood through the {\\lambda} calculus
      and the Turing/Church thesis. However, there are certain recursive functions
      that cannot be fully understood or predicted by other algorithms due to the
      loss of information during logical-arithmetic operations. In other words, the
      behaviour of these functions cannot be completely determined at every stage
      of the computation due to a lack of information in their definition. While there
      are some cases where the behaviour of recursive functions is highly predictable,
      the lack of information in most cases makes it impossible for algorithms to
      determine if a program will halt or not. This inability to predict the outcome
      of the computation is the essence of the halting problem of the Turing machine.
      Even in cases where more information is available about the program, it is still
      difficult to determine with certainty if the program will halt or not. This
      also highlights the importance of the Turing oracle machine, which introduces
      information from outside the computation to compensate for the lack of information
      and ultimately decide the result of the computation.", "venue": "arXiv.org",
      "year": 2022, "referenceCount": 30, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2022-02-14", "journal": {"name": "ArXiv",
      "volume": "abs/2204.00563"}, "authors": [{"authorId": "93077307", "name": "Ya.
      S. Lapin"}]}, {"paperId": "37371d64ae7a73f8bad43482dce40fa6485d9d6f", "externalIds":
      {"DBLP": "journals/corr/abs-2205-03949", "ArXiv": "2205.03949", "DOI": "10.48550/arXiv.2205.03949",
      "CorpusId": 248665550}, "corpusId": 248665550, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/37371d64ae7a73f8bad43482dce40fa6485d9d6f",
      "title": "Turing machine interaction problem", "abstract": "\u0410\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u044f.
      The article introduces some ideas for solving special cases of the following
      problem, proposed in a somewhat generalized form by Marcus Hutter in 2000. Given
      two Turing machines A and C, it is required to build a Turing machine B, such
      that after interacting of A and B on a shared tape for a fixed number of iterations,
      the machine C outputs 1 on the communication protocol of A and B. Details in
      the introduction.", "venue": "arXiv.org", "year": 2022, "referenceCount": 6,
      "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2022-05-08", "journal":
      {"name": "ArXiv", "volume": "abs/2205.03949"}, "authors": [{"authorId": "2284734",
      "name": "M. Matdinov"}]}, {"paperId": "cc3461f286d57aea512837ed2d88d11f552efb5f",
      "externalIds": {"DBLP": "journals/corr/abs-2212-11834", "ArXiv": "2212.11834",
      "DOI": "10.48550/arXiv.2212.11834", "CorpusId": 254974098}, "corpusId": 254974098,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/cc3461f286d57aea512837ed2d88d11f552efb5f",
      "title": "Real-valued affine automata compute beyond Turing machines", "abstract":
      "We show that bounded-error affine finite automata recognize uncountably many
      (and so some non-Turing recognizable) languages when using real-valued transitions.",
      "venue": "arXiv.org", "year": 2022, "referenceCount": 30, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2022-12-22", "journal": {"name": "ArXiv", "volume": "abs/2212.11834"}, "authors":
      [{"authorId": "1969092", "name": "A. Yakary\u0131lmaz"}]}, {"paperId": "246810f567b3e49164b1ffdedc911d6af0d1b144",
      "externalIds": {"ArXiv": "2206.06419", "DBLP": "journals/corr/abs-2206-06419",
      "DOI": "10.48550/arXiv.2206.06419", "CorpusId": 249642563}, "corpusId": 249642563,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/246810f567b3e49164b1ffdedc911d6af0d1b144",
      "title": "A Relative Church-Turing-Deutsch Thesis from Special Relativity and
      Undecidability", "abstract": "Beginning with Turing\u2019s seminal work in 1950,
      arti\ufb01cial intelligence pro-poses that consciousness can be simulated by
      a Turing machine. This implies a potential theory of everything where the universe
      is a simulation on a computer, which begs the question of whether we can prove
      we exist in a simulation. In this work, we construct a relative model of computation
      where a computable local machine is simulated by a global , classical Turing
      machine. We show that the problem of the local machine computing simulation
      properties of its global simulator is undecidable in the same sense as the Halting
      problem. Then, we show that computing the time, space, or error accumulated
      by the global simulator are simulation properties and therefore are undecidable.
      These simulation properties give rise to special relativistic e\ufb00ects in
      the relative model which we use to construct a relative Church-Turing-Deutsch
      thesis where a global, classical Turing machine computes quantum mechanics for
      a local machine with the same constant-time local computational complexity as
      experienced in our universe.", "venue": "arXiv.org", "year": 2022, "referenceCount":
      17, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Physics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2022-06-13", "journal":
      {"name": "ArXiv", "volume": "abs/2206.06419"}, "authors": [{"authorId": "2142506804",
      "name": "Blake A. Wilson"}, {"authorId": "2043408800", "name": "Ethan Dickey"},
      {"authorId": "2170169648", "name": "Vaishnavi Iyer"}, {"authorId": "1699217",
      "name": "S. Kais"}]}, {"paperId": "1382cd1a16b001cbb5a298d4458b788c2f0a6ffa",
      "externalIds": {"DBLP": "journals/corr/abs-2211-13087", "ArXiv": "2211.13087",
      "DOI": "10.48550/arXiv.2211.13087", "CorpusId": 253801749}, "corpusId": 253801749,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/1382cd1a16b001cbb5a298d4458b788c2f0a6ffa",
      "title": "Human or Machine? Turing Tests for Vision and Language", "abstract":
      "As AI algorithms increasingly participate in daily activities that used to
      be the sole province of humans, we are inevitably called upon to consider how
      much machines are really like us. To address this question, we turn to the Turing
      test and systematically benchmark current AIs in their abilities to imitate
      humans. We establish a methodology to evaluate humans versus machines in Turing-like
      tests and systematically evaluate a representative set of selected domains,
      parameters, and variables. The experiments involved testing 769 human agents,
      24 state-of-the-art AI agents, 896 human judges, and 8 AI judges, in 21,570
      Turing tests across 6 tasks encompassing vision and language modalities. Surprisingly,
      the results reveal that current AIs are not far from being able to impersonate
      human judges across different ages, genders, and educational levels", "venue":
      "arXiv.org", "year": 2022, "referenceCount": 78, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2022-11-23", "journal": {"name": "ArXiv",
      "volume": "abs/2211.13087"}, "authors": [{"authorId": "2418491", "name": "Mengmi
      Zhang"}, {"authorId": "104096295", "name": "Giorgia Dellaferrera"}, {"authorId":
      "2048021896", "name": "Ankur Sikarwar"}, {"authorId": "40263427", "name": "M.
      Armend\u00e1riz"}, {"authorId": "2168467358", "name": "Noga Mudrik"}, {"authorId":
      "2067433241", "name": "Prachi Agrawal"}, {"authorId": "7232330", "name": "Spandan
      Madan"}, {"authorId": "21570451", "name": "Andrei Barbu"}, {"authorId": "2118530836",
      "name": "Haochen Yang"}, {"authorId": "2191899809", "name": "T. Kumar"}, {"authorId":
      "2191899184", "name": "Meghna Sadwani"}, {"authorId": "2191899118", "name":
      "Stella Dellaferrera"}, {"authorId": "2191896327", "name": "Michele Pizzochero"},
      {"authorId": "40624376", "name": "H. Pfister"}, {"authorId": "2066787605", "name":
      "Gabriel Kreiman"}]}, {"paperId": "74d06c6a1c56d7bc819d057623d381edf9346736",
      "externalIds": {"ArXiv": "2207.05700", "DBLP": "journals/corr/abs-2207-05700",
      "DOI": "10.48550/arXiv.2207.05700", "CorpusId": 250450880}, "corpusId": 250450880,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/74d06c6a1c56d7bc819d057623d381edf9346736",
      "title": "Turing Machines cannot simulate the human mind", "abstract": "Can
      a Turing Machine simulate the human mind? If the Church-Turing thesis is assumed
      to be true, then a Turing Machine should be able to simulate the human mind.
      In this paper, I challenge that assumption by providing strong mathematical
      arguments against the Church-Turing thesis. First, I show that there are decision
      problems that are computable for humans, but uncomputable for Turing Machines.
      Next, using a thought experiment I show that a humanoid robot equipped with
      a Turing Machine as the control unit cannot perform all humanly doable physical
      tasks. Finally, I show that a quantum mechanical computing device involving
      sequential quantum wave function collapse can compute sequences that are uncomputable
      for Turing Machines. These results invalidate the Church-Turing thesis and lead
      to the conclusion that the human mind cannot be simulated by a Turing Machine.
      Connecting these results, I argue that quantum effects in the human brain are
      fundamental to the computing abilities of the human mind.", "venue": "arXiv.org",
      "year": 2022, "referenceCount": 27, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Philosophy", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2022-06-18", "journal": {"name": "ArXiv", "volume": "abs/2207.05700"},
      "authors": [{"authorId": "2175779537", "name": "Abhinav Muraleedharan"}]}, {"paperId":
      "bc0210361535562dac14987da8a91c7839533682", "externalIds": {"DBLP": "journals/corr/abs-2208-14755",
      "ArXiv": "2208.14755", "DOI": "10.48550/arXiv.2208.14755", "CorpusId": 251953492},
      "corpusId": 251953492, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/bc0210361535562dac14987da8a91c7839533682",
      "title": "Python Type Hints are Turing Complete", "abstract": "Grigore showed
      that Java generics are Turing complete by describing a reduction from Turing
      machines to Java subtyping. We apply Grigore''s algorithm to Python type hints
      and deduce that they are Turing complete. In addition, we present an alternative
      reduction in which the Turing machines are simulated in real time, resulting
      in significantly lower compilation times. Our work is accompanied by a Python
      implementation of both reductions that compiles Turing machines into Python
      subtyping machines.", "venue": "arXiv.org", "year": 2022, "referenceCount":
      11, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2022-08-31", "journal": {"name": "ArXiv", "volume": "abs/2208.14755"},
      "authors": [{"authorId": "38840709", "name": "Ori Roth"}]}, {"paperId": "335094aecbee9a8fabec0a1aa680ac411c88b596",
      "externalIds": {"DBLP": "journals/corr/abs-2206-14672", "DOI": "10.48550/arXiv.2206.14672",
      "CorpusId": 250113617}, "corpusId": 250113617, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/335094aecbee9a8fabec0a1aa680ac411c88b596",
      "title": "Is it possible not to cheat on the Turing Test: Exploring the potential
      and challenges for true natural language ''understanding'' by computers", "abstract":
      "The increasing sophistication of NLP models has renewed optimism regarding
      machines achieving a full human-like command of natural language. Whilst work
      in NLP/NLU may have made great strides in that direction, the lack of conceptual
      clarity in how \u2018understanding\u2019 is used in this and other disciplines
      have made it difficult to discern how close we actually are. A critical, interdisciplinary
      review of current approaches and remaining challenges is yet to be carried out.
      Beyond linguistic knowledge, this requires considering our species-specific
      capabilities to categorize, memorize, label and communicate our (sufficiently
      similar) embodied and situated experiences. Moreover, gauging the practical
      constraints requires critically analyzing the technical capabilities of current
      models, as well as deeper philosophical reflection on theoretical possibilities
      and limitations. In this paper, I unite all of these perspectives\u2014the philosophical,
      cognitive-linguistic, and technical\u2014to unpack the challenges involved in
      approaching true (human-like) language understanding. By unpacking the theoretical
      assumptions inherent in current approaches, I hope to illustrate how far we
      actually are from achieving this goal, if indeed it is the goal.", "venue":
      "arXiv.org", "year": 2022, "referenceCount": 122, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Philosophy", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
      "Review"], "publicationDate": null, "journal": {"name": "ArXiv", "volume": "abs/2206.14672"},
      "authors": [{"authorId": "1415024767", "name": "Lize Alberts"}]}, {"paperId":
      "18f7745ee7f7e8849d6d8250ad9d2d5e72661006", "externalIds": {"DBLP": "journals/corr/abs-2110-06211",
      "CorpusId": 239049903}, "corpusId": 239049903, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/18f7745ee7f7e8849d6d8250ad9d2d5e72661006",
      "title": "Diagonalization of Polynomial-Time Turing Machines Via Nondeterministic
      Turing Machine", "abstract": "\u2217 This work is a merger of arXiv:2110.06211
      and arXiv:2112.03677 \u2020 E-mail: The diagonalization technique was invented
      by Georg Cantor to show that there are more real numbers than algebraic numbers,
      and is very important in computer science. In this work, we enumerate all polynomial-time
      deterministic Turing machines and diagonalize over all of them by an universal
      nondeterministic Turing machine. As a result, we obtain that there is a language
      L d not accepted by any polynomial-time deterministic Turing machines but accepted
      by a nondeterministic Turing machine working within O ( n k ) for any k \u2208
      N 1 . By this, we further show that L d \u2208 N P . That is, we present a proof
      that P and N P di\ufb00er.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      42, "citationCount": 3, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": null, "journal": {"name": "ArXiv", "volume": "abs/2110.06211"},
      "authors": [{"authorId": "2325834", "name": "Tianrong Lin"}]}, {"paperId": "a58f2c90fbeaca660c9ce79f41a587bef20e7698",
      "externalIds": {"ArXiv": "2106.11394", "DBLP": "journals/corr/abs-2106-11394",
      "CorpusId": 235593224}, "corpusId": 235593224, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/a58f2c90fbeaca660c9ce79f41a587bef20e7698",
      "title": "A Turing Test for Transparency", "abstract": "A central goal of explainable
      artificial intelligence (XAI) is to improve the trust relationship in human-AI
      interaction. One assumption underlying research in transparent AI systems is
      that explanations help to better assess predictions of machine learning (ML)
      models, for instance by enabling humans to identify wrong predictions more efficiently.
      Recent empirical evidence however shows that explanations can have the opposite
      effect: When presenting explanations of ML predictions humans often tend to
      trust ML predictions even when these are wrong. Experimental evidence suggests
      that this effect can be attributed to how intuitive, or human, an AI or explanation
      appears. This effect challenges the very goal of XAI and implies that responsible
      usage of transparent AI methods has to consider the ability of humans to distinguish
      machine generated from human explanations. Here we propose a quantitative metric
      for XAI methods based on Turing''s imitation game, a Turing Test for Transparency.
      A human interrogator is asked to judge whether an explanation was generated
      by a human or by an XAI method. Explanations of XAI methods that can not be
      detected by humans above chance performance in this binary classification task
      are passing the test. Detecting such explanations is a requirement for assessing
      and calibrating the trust relationship in human-AI interaction. We present experimental
      results on a crowd-sourced text classification task demonstrating that even
      for basic ML models and XAI approaches most participants were not able to differentiate
      human from machine generated explanations. We discuss ethical and practical
      implications of our results for applications of transparent ML.", "venue": "arXiv.org",
      "year": 2021, "referenceCount": 11, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-06-21", "journal": {"name": "ArXiv",
      "volume": "abs/2106.11394"}, "authors": [{"authorId": "2170760", "name": "F.
      Biessmann"}, {"authorId": "2114421985", "name": "Viktor Treu"}]}, {"paperId":
      "5e9dddfc3d8dc685307518c1a36befdcaab1e719", "externalIds": {"ArXiv": "2102.01512",
      "DBLP": "journals/corr/abs-2102-01512", "DOI": "10.1371/journal.pone.0256025",
      "CorpusId": 231749705}, "corpusId": 231749705, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/5e9dddfc3d8dc685307518c1a36befdcaab1e719",
      "title": "Mimicry mechanism model of octopus epidermis pattern by inverse operation
      of Turing reaction model", "abstract": "Many cephalopods such as octopus and
      squid change their skin color purposefully within a very short time. Furthermore,
      it is widely known that some octopuses have the ability to change the color
      and unevenness of the skin and to mimic the surroundings in short time. However,
      much research has not been done on the entire mimicry mechanism in which the
      octopus recognizes the surrounding landscape and changes the skin pattern. It
      seems that there is no hypothetical model to explain the whole mimicry mechanism
      yet. In this study, the mechanism of octopus skin pattern formation was assumed
      to be based on the Turing model. Here, the pattern formation by the Turing model
      was realized by the equivalent filter calculation model using the cellular automaton,
      instead of directly solving the differential equations. It was shown that this
      model can create various patterns with two feature parameters. Furthermore,
      for the eyes recognition part where two features are extracted from the Turing
      pattern image, our study proposed a method that can be calculated back with
      small amount of calculation using the characteristics of the cellular Turing
      pattern model. These two calculations can be expressed in the same mathematical
      frame based on the cellular automaton model using the convolution filter. As
      a result, it can be created a model which is capable of extracting features
      from patterns and reconstructing patterns in a short time, the model is considered
      to be a basic model for considering the mimicry mechanism of octopus. Also,
      in terms of application to machine learning, it is considered that it shows
      the possibility of leading to a model with a small amount of learning calculation.",
      "venue": "arXiv.org", "year": 2021, "referenceCount": 21, "citationCount": 2,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0256025&type=printable",
      "status": "GOLD"}, "fieldsOfStudy": ["Biology", "Computer Science"], "s2FieldsOfStudy":
      [{"category": "Biology", "source": "external"}, {"category": "Computer Science",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2021-01-15", "journal":
      {"name": "ArXiv", "volume": "abs/2102.01512"}, "authors": [{"authorId": "144024246",
      "name": "T. Ishida"}]}, {"paperId": "4ab14b6585f85c2121ba5d3900e8c8d00fb80dfe",
      "externalIds": {"ArXiv": "2101.10907", "DBLP": "journals/corr/abs-2101-10907",
      "CorpusId": 231709582}, "corpusId": 231709582, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/4ab14b6585f85c2121ba5d3900e8c8d00fb80dfe",
      "title": "Exploring Rulial Space: The Case of Turing Machines", "abstract":
      "As an example of the concept of rulial space, we explore the case of simple
      Turing machines. We construct the rulial multiway graph which represents the
      behavior of all possible Turing machines with a certain class of rules. This
      graph (which is a Cayley graph of a \u201cTuring machine group\u201d) gives
      a map of the space of non\u2010deterministic Turing machines. We investigate
      the subgraph formed by deterministic machines, and explore the relationship
      to the P vs. NP problem. We also consider the implications of features of rulial
      space for physics, including estimating the maximum speed \u03c1 in rulial space,
      relations between rulial black holes and computational reducibility, and interpretations
      of hypercomputation.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      0, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Business",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-01-22", "journal": {"name": "ArXiv", "volume": "abs/2101.10907"}, "authors":
      [{"authorId": "143898851", "name": "S. Wolfram"}]}, {"paperId": "574cddb0d56fa84708b259dcd2d81473b810e7ad",
      "externalIds": {"ArXiv": "2104.08231", "DBLP": "journals/corr/abs-2104-08231",
      "CorpusId": 233289893}, "corpusId": 233289893, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/574cddb0d56fa84708b259dcd2d81473b810e7ad",
      "title": "An Adversarially-Learned Turing Test for Dialog Generation Models",
      "abstract": "The design of better automated dialogue evaluation metrics offers
      the potential of accelerate evaluation research on conversational AI. However,
      existing trainable dialogue evaluation models are generally restricted to classifiers
      trained in a purely supervised manner, which suffer a significant risk from
      adversarial attacking (e.g., a nonsensical response that enjoys a high classification
      score). To alleviate this risk, we propose an adversarial training approach
      to learn a robust model, ATT (Adversarial Turing Test), that discriminates machine-generated
      responses from human-written replies. In contrast to previous perturbation-based
      methods, our discriminator is trained by iteratively generating unrestricted
      and diverse adversarial examples using reinforcement learning. The key benefit
      of this unrestricted adversarial training approach is allowing the discriminator
      to improve robustness in an iterative attack-defense game. Our discriminator
      shows high accuracy on strong attackers including DialoGPT and GPT-3.", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 38, "citationCount": 1, "influentialCitationCount":
      1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-04-16", "journal": {"name": "ArXiv",
      "volume": "abs/2104.08231"}, "authors": [{"authorId": "71886367", "name": "Xiang
      Gao"}, {"authorId": "48378494", "name": "Yizhe Zhang"}, {"authorId": "1947267",
      "name": "Michel Galley"}, {"authorId": "66648221", "name": "Bill Dolan"}]},
      {"paperId": "a9449bf585120b910cff9e98a7d60d853581a255", "externalIds": {"ArXiv":
      "2112.02152", "DBLP": "journals/corr/abs-2112-02152", "CorpusId": 237209912},
      "corpusId": 237209912, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/a9449bf585120b910cff9e98a7d60d853581a255",
      "title": "A reliable Turing machine", "abstract": "We consider computations
      of a Turing machine subjected to noise. In every step, the action (the new state
      and the new content of the observed cell, the direction of the head movement)
      can di\ufb00er from that prescribed by the transition function with a small
      probability (independently of previous such events). We construct a universal
      1-tape Turing machine that in such noise with a low enough (constant) noise
      probability bound, performs arbitrarily large computations. For this unavoidably,
      the input needs to be encoded\u2014by a simple code depending on its size. The
      work uses a technique familiar from reliable cellular automata, complemented
      by some new ones.", "venue": "arXiv.org", "year": 2021, "referenceCount": 12,
      "citationCount": 1, "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2021-12-03", "journal":
      {"name": "ArXiv", "volume": "abs/2112.02152"}, "authors": [{"authorId": "1746115",
      "name": "Ilir \u00c7apuni"}, {"authorId": "1712160", "name": "P. G\u00e1cs"}]},
      {"paperId": "b910f67b8c2b2041c266305511e8a65a7c832b55", "externalIds": {"DBLP":
      "journals/corr/abs-2110-06119", "ArXiv": "2110.06119", "CorpusId": 238634713},
      "corpusId": 238634713, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/b910f67b8c2b2041c266305511e8a65a7c832b55",
      "title": "The Turing machine of a harmonic oscillator: from the code to the
      dynamic system", "abstract": "In this work we consider a dynamic system consisting
      of a damped harmonic oscillator and we formalize a Turing Machine whose definition
      in terms of states, alphabet and transition rules, can be considered equivalent
      to that of the oscillator. We prove that the Turing Machine of a FOR loop corresponds
      to that of the oscillator and we ask ourselves if it is possible to obtain the
      dynamic system of the harmonic oscillator as a physical realization of the FOR
      loop. We discuss the relationship between the results found and the science
      of Can and Can\u2019t. We discuss the possibility of an evolution of computer
      science also towards non-computerized specialized machines whose operating principle
      is designed as an automatic process starting from a source code instead of as
      a work of human ingenuity. The approach to the implementation of algorithms
      in dynamic systems instead of universal computers can be particularly interesting
      for the field of both diagnostic and implantable medical devices.", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 10, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Physics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
      "external"}, {"category": "Physics", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-10-01", "journal": {"name": "ArXiv", "volume": "abs/2110.06119"},
      "authors": [{"authorId": "3358162", "name": "F. Sisini"}, {"authorId": "2132056040",
      "name": "Valentina Sisini"}]}, {"paperId": "bb1fe9432657a641635fa745de9fc0d1f22316ac",
      "externalIds": {"ArXiv": "2110.02279", "DBLP": "journals/corr/abs-2110-02279",
      "CorpusId": 238408146}, "corpusId": 238408146, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/bb1fe9432657a641635fa745de9fc0d1f22316ac",
      "title": "Turing approximations, toric isometric embeddings & manifold convolutions",
      "abstract": "Convolutions are fundamental elements in deep learning architectures.
      Here, we present a theoretical framework for combining extrinsic and intrinsic
      approaches to manifold convolution through isometric embeddings into tori. In
      this way, we define a convolution operator for a manifold of arbitrary topology
      and dimension. We also explain geometric and topological conditions that make
      some local definitions of convolutions which rely on translating filters along
      geodesic paths on a manifold, computationally intractable. A result of Alan
      Turing from 1938 underscores the need for such a toric isometric embedding approach
      to achieve a global definition of convolution on computable, finite metric space
      approximations to a smooth manifold.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      61, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Mathematics",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2021-10-05", "journal":
      {"name": "ArXiv", "volume": "abs/2110.02279"}, "authors": [{"authorId": "2066256143",
      "name": "P. Su''arez-Serrato"}]}, {"paperId": "37c37255fcdfea3dc18cb360f3c27643710ae072",
      "externalIds": {"DBLP": "journals/corr/abs-2110-01415", "ArXiv": "2110.01415",
      "CorpusId": 238259586}, "corpusId": 238259586, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/37c37255fcdfea3dc18cb360f3c27643710ae072",
      "title": "Compiling Turing Machines into Storage Modification Machines", "abstract":
      "It is well known that Sch\\\"onhage''s Storage Modification Machines (SMM)
      can simulate Turing Machines (TM) since Sch\\\"onhage''s original proof of the
      Turing completeness of the eponymous machines. We propose a simple transformation
      of TM into SMM, setting the base for a straightforward TM-to-SMM compiler.",
      "venue": "arXiv.org", "year": 2021, "referenceCount": 7, "citationCount": 1,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Business", "source": "s2-fos-model"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-09-28", "journal": {"name": "ArXiv",
      "volume": "abs/2110.01415"}, "authors": [{"authorId": "34795986", "name": "J.
      Chauvet"}]}, {"paperId": "cbddbb34da264c489eb307f49143044fae3a785a", "externalIds":
      {"DBLP": "journals/corr/abs-2110-03279", "ArXiv": "2110.03279", "CorpusId":
      238419398}, "corpusId": 238419398, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/cbddbb34da264c489eb307f49143044fae3a785a",
      "title": "Polynomial Turing Kernels for Clique with an Optimal Number of Queries",
      "abstract": "A polynomial Turing kernel for some parameterized problem P is
      a polynomial-time algorithm that solves P using queries to an oracle of P whose
      sizes are upper-bounded by some polynomial in the parameter. Here the term \u201cpolynomial\u201d
      refers to the bound on the query sizes, as the running time of any kernel is
      required to be polynomial. One of the most important open goals in parameterized
      complexity is to understand the applicability and limitations of polynomial
      Turing Kernels. As any fixed-parameter tractable problem admits a Turing kernel
      of some size, the focus has mostly being on determining which problems admit
      such kernels whose query sizes can be indeed bounded by some polynomial. In
      this paper we take a different approach, and instead focus on the number of
      queries that a Turing kernel uses, assuming it is restricted to using only polynomial
      sized queries. Our study focuses on one the main problems studied in parameterized
      complexity, the Clique problem: Given a graph G and an integer k, determine
      whether there are k pairwise adjacent vertices in G. We show that Clique parameterized
      by several structural parameters exhibits the following phenomena: \u2022 It
      admits polynomial Turing kernels which use a sublinear number of queries, namely
      O(n/ log(n)) queries where n is the total size of the graph and c is any constant.
      This holds even for a very restrictive type of Turing kernels which we call
      OR-kernels. \u2022 It does not admit polynomial Turing kernels which use O(n)
      queries, unless NP \u2286 coNP / poly. For proving the second item above, we
      develop a new framework for bounding the number of queries needed by polynomial
      Turing kernels. This framework is inspired by the standard lower bounds framework
      for Karp kernels, and while it is quite similar, it still requires some novel
      ideas to allow its extension to the Turing setting.", "venue": "arXiv.org",
      "year": 2021, "referenceCount": 27, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-10-07", "journal": {"name": "ArXiv", "volume": "abs/2110.03279"}, "authors":
      [{"authorId": "1866810", "name": "T. Fluschnik"}, {"authorId": "35676871", "name":
      "Klaus Heeger"}, {"authorId": "1736630", "name": "D. Hermelin"}]}, {"paperId":
      "040c88bc1ed507c42d995d45b545ab86205ef1c4", "externalIds": {"ArXiv": "2112.03677",
      "DBLP": "journals/corr/abs-2112-03677", "CorpusId": 244920640}, "corpusId":
      244920640, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/040c88bc1ed507c42d995d45b545ab86205ef1c4",
      "title": "On Baker-Gill-Solovay Oracle Turing Machines and Relativization Barrier",
      "abstract": "This work analyses the so-called\"Relativization Barrier\"with
      respect to the Baker-Gill-Solovay oracle Turing machine. We show that the {\\em
      diagonalization} technique is a valid mathematical proof technique, but it has
      some prerequisites when referring to the\"relativization barrier.\"", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 23, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Business", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-12-07", "journal": {"name": "ArXiv", "volume": "abs/2112.03677"},
      "authors": [{"authorId": "2325834", "name": "Tianrong Lin"}]}, {"paperId": "1d6b35c73bcdbe0a55de3ce5d9b8a5edf3ca1a58",
      "externalIds": {"DBLP": "journals/corr/abs-2112-13205", "ArXiv": "2112.13205",
      "CorpusId": 245502640}, "corpusId": 245502640, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/1d6b35c73bcdbe0a55de3ce5d9b8a5edf3ca1a58",
      "title": "New Computing Model of GNeTM Turing Machine On Solving Even Goldbach
      Conjecture", "abstract": "Based on the propositional description of even Goldbach
      conjecture, in order to verify the truth of even Goldbach conjecture, we will
      deeply discuss this question and present a new computing model of GNeT M Turing
      Machine. This paper proves the infinite existence of even Goldbach\u2019s conjecture
      and obtains the following new results: 1. The criterion of general probability
      speculation of the existence judgment for even Goldbach conjecture is studied,
      and which at least have a formula satisfy the deduction result of matching requirements
      for even Goldbach conjecture in the model mod \u2261 M (Ne). 2. In the controller
      of the GNeT M model, the algorithm problem of the prime matching rule is given,
      regardless of whether the computer can be recursively solved, the rule algorithm
      for designing prime numbers in controllers is computer recursively solvable.
      3. The judgment problem that about even Goldbach conjecture whether infinite
      existence is studied. The new research result has shown that according to the
      constitution model of the full arranged matrix of given even number Ne, and
      if only given an even number Ne, it certainly exists the matrix model Mod \u2261
      X (p) and is proved to be equivalent. Therefore, it proves indirectly that the
      model GNeT M does not exist halting problem, and it also indicate that the even
      Goldbach conjecture is infinity existence.", "venue": "arXiv.org", "year": 2021,
      "referenceCount": 18, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-12-25", "journal": {"name": "ArXiv", "volume": "abs/2112.13205"},
      "authors": [{"authorId": "9431824", "name": "Bogang Lin"}]}, {"paperId": "bca2348d548194beb6134b337ac57d861cc4a3a6",
      "externalIds": {"ArXiv": "2104.05636", "DBLP": "journals/corr/abs-2104-05636",
      "CorpusId": 233210618}, "corpusId": 233210618, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/bca2348d548194beb6134b337ac57d861cc4a3a6",
      "title": "What Kind of Person Wins the Turing Award?", "abstract": "Computer
      science has grown rapidly since its inception in the 1950s and the pioneers
      in the field are celebrated annually by the A.M. Turing Award. In this paper,
      we attempt to shed light on the path to influential computer scientists by examining
      the characteristics of the 72 Turing Award laureates. To achieve this goal,
      we build a comprehensive dataset of the Turing Award laureates and analyze their
      characteristics, including their personal information, family background, academic
      background, and industry experience. The FP-Growth algorithm is used for frequent
      feature mining. Logistic regression plot, pie chart, word cloud and map are
      generated accordingly for each of the interesting features to uncover insights
      regarding personal factors that drive influential work in the field of computer
      science. In particular, we show that the Turing Award laureates are most commonly
      white, male, married, United States citizen, and received a PhD degree. Our
      results also show that the age at which the laureate won the award increases
      over the years; most of the Turing Award laureates did not major in computer
      science; birth order is strongly related to the winners'' success; and the number
      of citations is not as important as one would expect.", "venue": "arXiv.org",
      "year": 2021, "referenceCount": 30, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-04-04", "journal": {"name": "ArXiv",
      "volume": "abs/2104.05636"}, "authors": [{"authorId": "1850415250", "name":
      "Zhongkai Shangguan"}, {"authorId": "2109675164", "name": "Zihe Zheng"}, {"authorId":
      "2116783457", "name": "Jiebo Luo"}]}, {"paperId": "4df2147a463d6ed21aeb5bcb7a969da857ce6699",
      "externalIds": {"ArXiv": "2101.02203", "DBLP": "journals/corr/abs-2101-02203",
      "DOI": "10.32604/jqc.2020.014586", "CorpusId": 230800696}, "corpusId": 230800696,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/4df2147a463d6ed21aeb5bcb7a969da857ce6699",
      "title": "Translation of Quantum Circuits into Quantum Turing Machines for Deutsch
      and Deutsch-Jozsa Problems", "abstract": "We want in this article to show the
      usefulness of Quantum Turing Machine (QTM) in a high-level didactic context
      as well as in theoretical studies. We use QTM to show its equivalence with quantum
      circuit model for Deutsch and Deutsch-Jozsa algorithms. Further we introduce
      a strategy of translation from Quantum Circuit to Quantum Turing models by these
      examples. Moreover we illustrate some features of Quantum Computing such as
      superposition from a QTM point of view and starting with few simple examples
      very known in Quantum Circuit form.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      13, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Physics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Physics", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-01-06", "journal": {"name": "ArXiv", "volume": "abs/2101.02203"},
      "authors": [{"authorId": "35058013", "name": "Giuseppe Corrente"}]}, {"paperId":
      "39512882e97addfc5fbc1c733ff8494362041a2c", "externalIds": {"DBLP": "journals/corr/abs-2104-07454",
      "CorpusId": 233241236}, "corpusId": 233241236, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/39512882e97addfc5fbc1c733ff8494362041a2c",
      "title": "Memory Capacity of Neural Turing Machines with Matrix Representation",
      "abstract": "It is well known that recurrent neural networks (RNNs) faced limitations
      in learning longterm dependencies that have been addressed by memory structures
      in long short-term memory (LSTM) networks. Matrix neural networks feature matrix
      representation which inherently preserves the spatial structure of data and
      has the potential to provide better memory structures when compared to canonical
      neural networks that use vector representation. Neural Turing machines (NTMs)
      are novel RNNs that implement notion of programmable computers with neural network
      controllers to feature algorithms that have copying, sorting, and associative
      recall tasks. In this paper, we study augmentation of memory capacity with matrix
      representation of RNNs and NTMs (MatNTMs). We investigate if matrix representation
      has a better memory capacity than the vector representations in conventional
      neural networks. We use a probabilistic model of the memory capacity using Fisher
      information and investigate how the memory capacity for matrix representation
      networks are limited under various constraints, and in general, without any
      constraints. In the case of memory capacity without any constraints, we found
      that the upper bound on memory capacity to be N for an N\u00d7N state matrix.
      The results from our experiments using synthetic algorithmic tasks show that
      MatNTMs have a better learning capacity when compared to its counterparts.",
      "venue": "arXiv.org", "year": 2021, "referenceCount": 49, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      null, "journal": {"name": "ArXiv", "volume": "abs/2104.07454"}, "authors": [{"authorId":
      "2077430207", "name": "Animesh Renanse"}, {"authorId": "38743363", "name": "Rohitash
      Chandra"}, {"authorId": "2109552408", "name": "Alok Sharma"}]}, {"paperId":
      "314e76f1df702702cc2de8661caebab1beb5a32d", "externalIds": {"DBLP": "journals/corr/abs-2112-13345",
      "ArXiv": "2112.13345", "CorpusId": 245502188}, "corpusId": 245502188, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/314e76f1df702702cc2de8661caebab1beb5a32d",
      "title": "Resource dependent undecidability: computability landscape of distinct
      Turing theories", "abstract": "Can a problem undecidable with classical resources
      be decidable with quantum ones? The answer expected is no; as both being Turing
      theories, they should not solve the Halting problem - a problem unsolvable by
      any Turing machine. Yet, we provide an affirmative answer to the aforesaid question.
      We come up with a novel logical structure to formulate infinitely many such
      problems for any pair of distinct Turing theories, including but not limited
      to the classical and quantum theories. Importantly, a class of other decision
      problems, such as the Halting one, remains unsolvable in all those theories.
      The apparent paradoxical situation gets resolved once it is perceived that the
      reducibility of Halting problem changes with varying resources available for
      computations in different theories. In the end, we propose a multi-agent game
      where winnability of the player having access to only classical resources is
      undecidable while quantum resources provide a perfect winning strategy.", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 39, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Physics", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Physics", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-12-26", "journal": {"name": "ArXiv", "volume": "abs/2112.13345"}, "authors":
      [{"authorId": "2048120813", "name": "Airin Antony"}]}, {"paperId": "49b19576b71cc25877e341d7b7267349de3c2cca",
      "externalIds": {"ArXiv": "2105.02124", "DBLP": "journals/corr/abs-2105-02124",
      "CorpusId": 233740023}, "corpusId": 233740023, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/49b19576b71cc25877e341d7b7267349de3c2cca",
      "title": "Intrinsic Propensity for Vulnerability in Computers? Arbitrary Code
      Execution in the Universal Turing Machine", "abstract": "The universal Turing
      machine is generally considered to be the simplest, most abstract model of a
      computer. This paper reports on the discovery of an accidental arbitrary code
      execution vulnerability in Marvin Minsky''s 1967 implementation of the universal
      Turing machine. By submitting crafted data, the machine may be coerced into
      executing user-provided code. The article presents the discovered vulnerability
      in detail and discusses its potential implications. To the best of our knowledge,
      an arbitrary code execution vulnerability has not previously been reported for
      such a simple system.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      19, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-04-22", "journal": {"name": "ArXiv", "volume": "abs/2105.02124"},
      "authors": [{"authorId": "144124156", "name": "Pontus Johnson"}]}, {"paperId":
      "577349e25391605c0318b3583983e0f35fe5acae", "externalIds": {"DBLP": "journals/corr/abs-2103-04961",
      "ArXiv": "2103.04961", "CorpusId": 232147860}, "corpusId": 232147860, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/577349e25391605c0318b3583983e0f35fe5acae",
      "title": "Multiway Turing Machines", "abstract": "Multiway Turing machines (also
      known as nondeterministic Turing machines or NDTMs) with explicit, simple rules
      are studied. Even very simple rules are found to generate complex behavior,
      characterized by complex multiway graphs, that can be visualized in multispace
      that combines \u201ctape\u201d and branchial space. The threshold for complex
      behavior appears to be machines with just s = 1 head states, k = 2 tape colors
      and p = 3 possible cases, and such machines may potentially be universal. Other
      characteristics of multiway Turing machines are also studied, including causal
      invariance, cyclic tapes and generalized busy beaver problems. Multiway Turing
      machines provide minimal examples of a variety of issues encountered in both
      concurrent computing and the theory of observers in quantum mechanics, especially
      in our recent models of physics.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Business",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-03-08", "journal": {"name": "ArXiv", "volume": "abs/2103.04961"}, "authors":
      [{"authorId": "143898851", "name": "S. Wolfram"}]}, {"paperId": "58f3f0d11ddfd2243d64f9bf1abb761abda2a131",
      "externalIds": {"DBLP": "journals/corr/abs-2103-14013", "ArXiv": "2103.14013",
      "CorpusId": 232352473}, "corpusId": 232352473, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/58f3f0d11ddfd2243d64f9bf1abb761abda2a131",
      "title": "Set Turing Machines", "abstract": "In this paper we define a notion
      of Turing computability for class functions, i.e., functions that operate on
      arbitrary sets. We generalize the notion of a Turing machine to the set Turing
      machine. Set Turing machines operate on a class size tape. We represent sets
      by placing marks in the cells of the set Turing machine tape. Instead of being
      indexed by N or Z, the tapes cells are indexed by finite sequences of ordinals.
      For a marking of the cells to represent a set, the markings have the structure
      of a tree which mirrors the transitive closure of the set. Our conception depends
      on both the Axiom of Choice and the Axiom of Foundation. Representations of
      sets as marks on the set Turing machine tape exist by the Axiom of Choice. The
      representations are well founded by the Axiom of Foundation. Using the concepts
      of the set Turing machines and the encoding of sets by marks on the set Turing
      machine tape, we define the Turing computable class functions denoted TUR. We
      also define the collection of recursive class functions, REC, a generalization
      of the primitive recursive set functions as defined in [JK]. The class functions
      in REC are analogous to the recursive functions on N. We will prove some elementary
      properties about REC. In the last section we prove our main theorem that TUR
      = REC.", "venue": "arXiv.org", "year": 2021, "referenceCount": 3, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-03-25", "journal": {"name": "ArXiv",
      "volume": "abs/2103.14013"}, "authors": [{"authorId": "2933043", "name": "Garvin
      Melles"}]}, {"paperId": "01baca4fa7ad5d28b95f6f72fe33de9a34633bc6", "externalIds":
      {"MAG": "2920798074", "ArXiv": "1903.07486", "DBLP": "journals/corr/abs-1903-07486",
      "CorpusId": 81981887}, "corpusId": 81981887, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/01baca4fa7ad5d28b95f6f72fe33de9a34633bc6",
      "title": "Dissecting the NVidia Turing T4 GPU via Microbenchmarking", "abstract":
      "In 2019, the rapid rate at which GPU manufacturers refresh their designs, coupled
      with their reluctance to disclose microarchitectural details, is still a hurdle
      for those software designers who want to extract the highest possible performance.
      Last year, these very reasons motivated us to dissect the Volta GPU architecture
      using microbenchmarks. \nThe introduction in August 2018 of Turing, NVidia''s
      latest architecture, pressed us to update our study. In this report, we examine
      Turing and compare it quantitatively against previous NVidia GPU generations.
      Specifically, we study the T4 GPU: a low-power board aiming at inference applications.
      We describe its improvements against its inference-oriented predecessor: the
      P4 GPU based on the Pascal architecture. Both T4 and P4 GPUs achieve significantly
      higher frequency-per-Watt figures than their full-size counterparts. \nWe study
      the performance of the T4''s TensorCores, finding a much higher throughput on
      low-precision operands than on the P4 GPU. We reveal that Turing introduces
      new instructions that express matrix math more succinctly. We map Turing''s
      instruction space, finding the same encoding as Volta, and additional instructions.
      We reveal that the Turing TU104 chip has the same memory hierarchy depth as
      the Volta GV100; cache levels sizes on the TU104 are frequently twice as large
      as those found on the Pascal GP104. We benchmark each constituent of the T4
      memory hierarchy and find substantial overall performance improvements over
      its P4 predecessor. We studied how clock throttling affects compute-intensive
      workloads that hit power or thermal limits. \nMany of our findings are novel,
      published here for the first time. All of them can guide high-performance software
      developers get closer to the GPU''s peak performance.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 8, "citationCount": 75, "influentialCitationCount":
      13, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-03-18", "journal": {"name": "ArXiv",
      "volume": "abs/1903.07486"}, "authors": [{"authorId": "48813086", "name": "Zhe
      Jia"}, {"authorId": "138304679", "name": "Marco Maggioni"}, {"authorId": "2109849147",
      "name": "Jeffrey K. Smith"}, {"authorId": "3277273", "name": "D. Scarpazza"}]},
      {"paperId": "2ca09ee92154b4480230654989a3ecec6b29ef10", "externalIds": {"DBLP":
      "journals/corr/abs-2111-05321", "ArXiv": "2111.05321", "CorpusId": 243860726},
      "corpusId": 243860726, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/2ca09ee92154b4480230654989a3ecec6b29ef10",
      "title": "Turing-Universal Learners with Optimal Scaling Laws", "abstract":
      "For a given distribution, learning algorithm, and performance metric, the rate
      of convergence (or data-scaling law) is the asymptotic behavior of the algorithm''s
      test performance as a function of number of train samples. Many learning methods
      in both theory and practice have power-law rates, i.e. performance scales as
      $n^{-\\alpha}$ for some $\\alpha>0$. Moreover, both theoreticians and practitioners
      are concerned with improving the rates of their learning algorithms under settings
      of interest. We observe the existence of a\"universal learner\", which achieves
      the best possible distribution-dependent asymptotic rate among all learning
      algorithms within a specified runtime (e.g. $O(n^2)$), while incurring only
      polylogarithmic slowdown over this runtime. This algorithm is uniform, and does
      not depend on the distribution, and yet achieves best-possible rates for all
      distributions. The construction itself is a simple extension of Levin''s universal
      search (Levin, 1973). And much like universal search, the universal learner
      is not at all practical, and is primarily of theoretical and philosophical interest.",
      "venue": "arXiv.org", "year": 2021, "referenceCount": 30, "citationCount": 1,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-11-09", "journal": {"name": "ArXiv",
      "volume": "abs/2111.05321"}, "authors": [{"authorId": "2181918", "name": "Preetum
      Nakkiran"}]}, {"paperId": "79bae31ed966a7a97dbea7292e17fa6274122100", "externalIds":
      {"ArXiv": "2305.20010", "DBLP": "journals/corr/abs-2305-20010", "DOI": "10.48550/arXiv.2305.20010",
      "CorpusId": 258987666}, "corpusId": 258987666, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/79bae31ed966a7a97dbea7292e17fa6274122100",
      "title": "Human or Not? A Gamified Approach to the Turing Test", "abstract":
      "We present\"Human or Not?\", an online game inspired by the Turing test, that
      measures the capability of AI chatbots to mimic humans in dialog, and of humans
      to tell bots from other humans. Over the course of a month, the game was played
      by over 1.5 million users who engaged in anonymous two-minute chat sessions
      with either another human or an AI language model which was prompted to behave
      like humans. The task of the players was to correctly guess whether they spoke
      to a person or to an AI. This largest scale Turing-style test conducted to date
      revealed some interesting facts. For example, overall users guessed the identity
      of their partners correctly in only 68% of the games. In the subset of the games
      in which users faced an AI bot, users had even lower correct guess rates of
      60% (that is, not much higher than chance). This white paper details the development,
      deployment, and results of this unique experiment. While this experiment calls
      for many extensions and refinements, these findings already begin to shed light
      on the inevitable near future which will commingle humans and AI.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 4, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-05-31", "journal": {"name": "ArXiv",
      "volume": "abs/2305.20010"}, "authors": [{"authorId": "2090357207", "name":
      "Daniel Jannai"}, {"authorId": "2218579362", "name": "Amos Meron"}, {"authorId":
      "1412384990", "name": "Barak Lenz"}, {"authorId": "152754428", "name": "Yoav
      Levine"}, {"authorId": "1701353", "name": "Y. Shoham"}]}, {"paperId": "74de8a496f9e921464044b9050f73e6b17130ca9",
      "externalIds": {"DBLP": "journals/corr/abs-2301-12556", "ArXiv": "2301.12556",
      "DOI": "10.48550/arXiv.2301.12556", "CorpusId": 256461497}, "corpusId": 256461497,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/74de8a496f9e921464044b9050f73e6b17130ca9",
      "title": "A Log-Sensitive Encoding of Turing Machines in the \u03bb-Calculus",
      "abstract": "This note modifies the reference encoding of Turing machines in
      the $\\lambda$-calculus by Dal Lago and Accattoli, which is tuned for time efficiency,
      as to accommodate logarithmic space. There are two main changes: Turing machines
      now have *two* tapes, an input tape and a work tape, and the input tape is encoded
      differently, because the reference encoding comes with a linear space overhead
      for managing tapes, which is excessive for studying logarithmic space.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 7, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-01-29", "journal": {"name": "ArXiv",
      "volume": "abs/2301.12556"}, "authors": [{"authorId": "1745985", "name": "Beniamino
      Accattoli"}, {"authorId": "9127840", "name": "Ugo Dal Lago"}, {"authorId": "41067044",
      "name": "G. Vanoni"}]}, {"paperId": "0cbc09097c340f3d54e30dba7347abe3129afa53",
      "externalIds": {"DBLP": "journals/corr/abs-2305-04312", "DOI": "10.48550/arXiv.2305.04312",
      "CorpusId": 258558186}, "corpusId": 258558186, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/0cbc09097c340f3d54e30dba7347abe3129afa53",
      "title": "Human or Machine: Reflections on Turing-Inspired Testing for the Everyday",
      "abstract": ": In his seminal paper \"Computing Machinery and Intelligence\",
      Alan Turing introduced the \"imitation game\" as part of exploring the concept
      of machine intelligence. The Turing Test has since been the subject of much
      analysis, debate, re\ufb01nement and extension. Here we sidestep the question
      of whether a particular machine can be labeled intelligent, or can be said to
      match human capabilities in a given context. Instead, but inspired by Turing,
      we draw attention to the seemingly simpler challenge of determining whether
      one is interacting with a human or with a machine, in the context of everyday
      life. We are interested in re\ufb02ecting upon the importance of this Human-or-Machine
      question and the use one may make of a reliable answer thereto. Whereas Turing\u2019s
      original test is widely considered to be more of a thought experiment, the Human-or-Machine
      question as discussed here has obvious practical signi\ufb01cance. And while
      the jury is still not in regarding the possibility of machines that can mimic
      human behavior with high \ufb01delity in everyday contexts, we argue that near-term
      exploration of the issues raised here can contribute to development methods
      for computerized systems, and may also improve our understanding of human behavior
      in general.", "venue": "arXiv.org", "year": 2023, "referenceCount": 42, "citationCount":
      1, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      null, "journal": {"name": "ArXiv", "volume": "abs/2305.04312"}, "authors": [{"authorId":
      "145771081", "name": "D. Harel"}, {"authorId": "144118264", "name": "Assaf Marron"}]},
      {"paperId": "c05021041c7404bae171bf2d23b9708af977b8fa", "externalIds": {"DBLP":
      "journals/corr/abs-2303-17270", "ArXiv": "2303.17270", "DOI": "10.48550/arXiv.2303.17270",
      "CorpusId": 257833992}, "corpusId": 257833992, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/c05021041c7404bae171bf2d23b9708af977b8fa",
      "title": "The group of reversible Turing machines: subgroups, generators and
      computability", "abstract": "We study an abstract group of reversible Turing
      machines. In our model, each machine is interpreted as a homeomorphism over
      a space which represents a tape filled with symbols and a head carrying a state.
      These homeomorphisms can only modify the tape at a bounded distance around the
      head, change the state and move the head in a bounded way. We study three natural
      subgroups arising in this model: the group of finite-state automata, which generalizes
      the topological full groups studied in topological dynamics and the theory of
      orbit-equivalence; the group of oblivious Turing machines whose movement is
      independent of tape contents, which generalizes lamplighter groups and has connections
      to the study of universal reversible logical gates; and the group of elementary
      Turing machines, which are the machines which are obtained by composing finite-state
      automata and oblivious Turing machines. We show that both the group of oblivious
      Turing machines and that of elementary Turing machines are finitely generated,
      while the group of finite-state automata and the group of reversible Turing
      machines are not. We show that the group of elementary Turing machines has undecidable
      torsion problem. From this, we also obtain that the group of cellular automata
      (more generally, the automorphism group of any uncountable one-dimensional sofic
      subshift) contains a finitely-generated subgroup with undecidable torsion problem.
      We also show that the torsion problem is undecidable for the topological full
      group of a full $\\mathbb{Z}^d$-shift on a non-trivial alphabet if and only
      if $d \\geq 2$.", "venue": "arXiv.org", "year": 2023, "referenceCount": 40,
      "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-03-30", "journal":
      {"name": "ArXiv", "volume": "abs/2303.17270"}, "authors": [{"authorId": "102723089",
      "name": "S. Barbieri"}, {"authorId": "1753080", "name": "J. Kari"}, {"authorId":
      "1789048", "name": "Ville Salo"}]}, {"paperId": "1ab5ef5ab882aabb392454fc6c7ee542a4b1e830",
      "externalIds": {"DBLP": "journals/corr/abs-2008-07743", "ArXiv": "2008.07743",
      "MAG": "3078290683", "CorpusId": 221151031}, "corpusId": 221151031, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/1ab5ef5ab882aabb392454fc6c7ee542a4b1e830",
      "title": "Turing Test and the Practice of Law: The Role of Autonomous Levels
      of AI Legal Reasoning", "abstract": "Artificial Intelligence (AI) is increasingly
      being applied to law and a myriad of legal tasks amid attempts to bolster AI
      Legal Reasoning (AILR) autonomous capabilities. A major question that has generally
      been unaddressed involves how we will know when AILR has achieved autonomous
      capacities. The field of AI has grappled with similar quandaries over how to
      assess the attainment of Artificial General Intelligence (AGI), a persistently
      discussed issue among scholars since the inception of AI, with the Turing Test
      communally being considered as the bellwether for ascertaining such matters.
      This paper proposes a variant of the Turing Test that is customized for specific
      use in the AILR realm, including depicting how this famous gold standard of
      AI fulfillment can be robustly applied across the autonomous levels of AI Legal
      Reasoning.", "venue": "arXiv.org", "year": 2020, "referenceCount": 57, "citationCount":
      8, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Law", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2020-08-18", "journal":
      {"name": "ArXiv", "volume": "abs/2008.07743"}, "authors": [{"authorId": "10776465",
      "name": "L. Eliot"}]}, {"paperId": "2da3a84e72a2973504cd9cf1c0a377f5a5a91f09",
      "externalIds": {"ArXiv": "2303.14310", "DBLP": "journals/corr/abs-2303-14310",
      "DOI": "10.48550/arXiv.2303.14310", "CorpusId": 257766379}, "corpusId": 257766379,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/2da3a84e72a2973504cd9cf1c0a377f5a5a91f09",
      "title": "GPT is becoming a Turing machine: Here are some ways to program it",
      "abstract": "We demonstrate that, through appropriate prompting, GPT-3 family
      of models can be triggered to perform iterative behaviours necessary to execute
      (rather than just write or recall) programs that involve loops, including several
      popular algorithms found in computer science curricula or software developer
      interviews. We trigger execution and description of Iterations by Regimenting
      Self-Attention (IRSA) in one (or a combination) of three ways: 1) Using strong
      repetitive structure in an example of an execution path of a target program
      for one particular input, 2) Prompting with fragments of execution paths, and
      3) Explicitly forbidding (skipping) self-attention to parts of the generated
      text. On a dynamic program execution, IRSA leads to larger accuracy gains than
      replacing the model with the much more powerful GPT-4. IRSA has promising applications
      in education, as the prompts and responses resemble student assignments in data
      structures and algorithms classes. Our findings hold implications for evaluating
      LLMs, which typically target the in-context learning: We show that prompts that
      may not even cover one full task example can trigger algorithmic behaviour,
      allowing solving problems previously thought of as hard for LLMs, such as logical
      puzzles. Consequently, prompt design plays an even more critical role in LLM
      performance than previously recognized.", "venue": "arXiv.org", "year": 2023,
      "referenceCount": 45, "citationCount": 4, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-03-25", "journal": {"name": "ArXiv", "volume": "abs/2303.14310"},
      "authors": [{"authorId": "2156583836", "name": "A. Jojic"}, {"authorId": "47197370",
      "name": "Zhen Wang"}, {"authorId": "1698689", "name": "N. Jojic"}]}, {"paperId":
      "da7a38d370b7e3d00ab2869b4832d8dda8fb94d3", "externalIds": {"DBLP": "journals/corr/abs-2301-11632",
      "ArXiv": "2301.11632", "DOI": "10.48550/arXiv.2301.11632", "CorpusId": 256358733},
      "corpusId": 256358733, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/da7a38d370b7e3d00ab2869b4832d8dda8fb94d3",
      "title": "Turing Machines Equipped with CTC in Physical Universes", "abstract":
      "We study the paradoxical aspects of closed time-like curves and their impact
      on the theory of computation. After introducing the $\\text{TM}_\\text{CTC}$,
      a classical Turing machine benefiting CTCs for backward time travel, Aaronson
      et al. proved that $\\text{P} = \\text{PSPACE}$ and the $\\Delta_2$ sets, such
      as the halting problem, are computable within this computational model. Our
      critical view is the physical consistency of this model, which leads to proposing
      the strong axiom, explaining that every particle rounding on a CTC will be destroyed
      before returning to its starting time, and the weak axiom, describing the same
      notion, particularly for Turing machines. We claim that in a universe containing
      CTCs, the two axioms must be true; otherwise, there will be an infinite number
      of any particle rounding on a CTC in the universe. An immediate result of the
      weak axiom is the incapability of Turing machines to convey information for
      a full round on a CTC, leading to the proposed $\\text{TM}_\\text{CTC}$ programs
      for the aforementioned corollaries failing to function. We suggest our solution
      for this problem as the data transferring hypothesis, which applies another
      $\\text{TM}_\\text{CTC}$ as a means for storing data. A prerequisite for it
      is the existence of the concept of Turing machines throughout time, which makes
      it appear infeasible in our universe. Then, we discuss possible physical conditions
      that can be held for a universe containing CTCs and conclude that if returning
      to an approximately equivalent universe by a CTC was conceivable, the above
      corollaries would be valid.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      18, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Physics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-01-27", "journal":
      {"name": "ArXiv", "volume": "abs/2301.11632"}, "authors": [{"authorId": "2203247815",
      "name": "Sara Babaee Khanehsar"}, {"authorId": "1793763", "name": "F. Didehvar"}]},
      {"paperId": "f0b12a333d1e630db0de5a1221f470cddd668229", "externalIds": {"DBLP":
      "journals/corr/abs-2307-15543", "ArXiv": "2307.15543", "DOI": "10.48550/arXiv.2307.15543",
      "CorpusId": 260316276}, "corpusId": 260316276, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/f0b12a333d1e630db0de5a1221f470cddd668229",
      "title": "Oracle Computability and Turing Reducibility in the Calculus of Inductive
      Constructions", "abstract": "We develop synthetic notions of oracle computability
      and Turing reducibility in the Calculus of Inductive Constructions (CIC), the
      constructive type theory underlying the Coq proof assistant. As usual in synthetic
      approaches, we employ a definition of oracle computations based on meta-level
      functions rather than object-level models of computation, relying on the fact
      that in constructive systems such as CIC all definable functions are computable
      by construction. Such an approach lends itself well to machine-checked proofs,
      which we carry out in Coq. There is a tension in finding a good synthetic rendering
      of the higher-order notion of oracle computability. On the one hand, it has
      to be informative enough to prove central results, ensuring that all notions
      are faithfully captured. On the other hand, it has to be restricted enough to
      benefit from axioms for synthetic computability, which usually concern first-order
      objects. Drawing inspiration from a definition by Andrej Bauer based on continuous
      functions in the effective topos, we use a notion of sequential continuity to
      characterise valid oracle computations. As main technical results, we show that
      Turing reducibility forms an upper semilattice, transports decidability, and
      is strictly more expressive than truth-table reducibility, and prove that whenever
      both a predicate $p$ and its complement are semi-decidable relative to an oracle
      $q$, then $p$ Turing-reduces to $q$.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-07-28", "journal": {"name": "ArXiv", "volume": "abs/2307.15543"}, "authors":
      [{"authorId": "24034340", "name": "Y. Forster"}, {"authorId": "3396228", "name":
      "Dominik Kirst"}, {"authorId": "2221296088", "name": "Niklas M\u00fcck"}]},
      {"paperId": "3452746bfda18dd59dad9ce5a5802f721a10a4d4", "externalIds": {"DBLP":
      "journals/corr/abs-2304-04498", "ArXiv": "2304.04498", "DOI": "10.48550/arXiv.2304.04498",
      "CorpusId": 258049252}, "corpusId": 258049252, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/3452746bfda18dd59dad9ce5a5802f721a10a4d4",
      "title": "Towards Digital Nature: Bridging the Gap between Turing Machine Objects
      and Linguistic Objects in LLMMs for Universal Interaction of Object-Oriented
      Descriptions", "abstract": "In this paper, we propose a novel approach to establish
      a connection between linguistic objects and classes in Large Language Model
      Machines (LLMMs) such as GPT3.5 and GPT4, and their counterparts in high level
      programming languages like Python. Our goal is to promote the development of
      Digital Nature: a worldview where digital and physical realities are seamlessly
      intertwined and can be easily manipulated by computational means. To achieve
      this, we exploit the inherent abstraction capabilities of LLMMs to build a bridge
      between human perception of the real world and the computational processes that
      mimic it. This approach enables ambiguous class definitions and interactions
      between objects to be realized in programming and ubiquitous computing scenarios.
      By doing so, we aim to facilitate seamless interaction between Turing Machine
      objects and Linguistic Objects, paving the way for universally accessible object
      oriented descriptions. We demonstrate a method for automatically transforming
      real world objects and their corresponding simulations into language simulable
      worlds using LLMMs, thus advancing the digital twin concept. This process can
      then be extended to high level programming languages, making the implementation
      of these simulations more accessible and practical. In summary, our research
      introduces a groundbreaking approach to connect linguistic objects in LLMMs
      with high level programming languages, allowing for the efficient implementation
      of real world simulations. This ultimately contributes to the realization of
      Digital Nature, where digital and physical worlds are interconnected, and objects
      and simulations can be effortlessly manipulated through computational means.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 23, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-04-10", "journal": {"name": "ArXiv", "volume": "abs/2304.04498"}, "authors":
      [{"authorId": "2059595927", "name": "Y. Ochiai"}, {"authorId": "2028904904",
      "name": "Naruya Kondo"}, {"authorId": "52567877", "name": "Tatsuki Fushimi"}]},
      {"paperId": "4c18561f8693330d0eaef3278fcceef205b1d5b5", "externalIds": {"DBLP":
      "journals/corr/abs-2306-16872", "ArXiv": "2306.16872", "DOI": "10.48550/arXiv.2306.16872",
      "CorpusId": 259287339}, "corpusId": 259287339, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/4c18561f8693330d0eaef3278fcceef205b1d5b5",
      "title": "Towards a Self-Replicating Turing Machine", "abstract": "We provide
      partial implementations of von Neumann''s universal constructor and universal
      copier, starting out with three types of simple building blocks using minimal
      assumptions. Using the same principles, we also construct Turing machines. Combining
      both, we arrive at a proposal for a self-replicating Turing machine. Our construction
      allows for mutations if desired, and we give a simple description language.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 15, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-06-29", "journal": {"name": "ArXiv", "volume": "abs/2306.16872"}, "authors":
      [{"authorId": "2494914", "name": "R. Lano"}]}, {"paperId": "8048a971e9795e2ad58f61359743ea150103cc7a",
      "externalIds": {"DBLP": "journals/corr/abs-2308-10578", "ArXiv": "2308.10578",
      "DOI": "10.48550/arXiv.2308.10578", "CorpusId": 261048980}, "corpusId": 261048980,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/8048a971e9795e2ad58f61359743ea150103cc7a",
      "title": "Weakly synchronous systems with three machines are Turing powerful",
      "abstract": "Communicating finite-state machines (CFMs) are a Turing powerful
      model of asynchronous message-passing distributed systems. In weakly synchronous
      systems, processes communicate through phases in which messages are first sent
      and then received, for each process. Such systems enjoy a limited form of synchronization,
      and for some communication models, this restriction is enough to make the reachability
      problem decidable. In particular, we explore the intriguing case of p2p (FIFO)
      communication, for which the reachability problem is known to be undecidable
      for four processes, but decidable for two. We show that the configuration reachability
      problem for weakly synchronous systems of three processes is undecidable. This
      result is heavily inspired by our study on the treewidth of the Message Sequence
      Charts (MSCs) that might be generated by such systems. In this sense, the main
      contribution of this work is a weakly synchronous system with three processes
      that generates MSCs of arbitrarily large treewidth.", "venue": "arXiv.org",
      "year": 2023, "referenceCount": 18, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-08-21", "journal": {"name": "ArXiv", "volume": "abs/2308.10578"}, "authors":
      [{"authorId": "1874844", "name": "C. Giusto"}, {"authorId": "2188740323", "name":
      "Davide Ferr''e"}, {"authorId": "2313341", "name": "\u00c9. Lozes"}, {"authorId":
      "1736014", "name": "N. Nisse"}]}, {"paperId": "35140379a7d94c875ac9fa354c5ae3882ad29282",
      "externalIds": {"DBLP": "journals/corr/abs-2306-12440", "ArXiv": "2306.12440",
      "DOI": "10.48550/arXiv.2306.12440", "CorpusId": 259225008}, "corpusId": 259225008,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/35140379a7d94c875ac9fa354c5ae3882ad29282",
      "title": "Sleptsov Nets are Turing-complete", "abstract": "The present paper
      proves that a Sleptsov net (SN) is Turing-complete, that considerably improves,
      with a brief construct, the previous result that a strong SN is Turing-complete.
      Remind that, unlike Petri nets, an SN always fires enabled transitions at their
      maximal firing multiplicity, as a single step, leaving for a nondeterministic
      choice of which fireable transitions to fire. A strong SN restricts nondeterministic
      choice to firing only the transitions having the highest firing multiplicity.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 3, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-06-17", "journal": {"name": "ArXiv", "volume": "abs/2306.12440"}, "authors":
      [{"authorId": "1791765", "name": "B. Berthomieu"}, {"authorId": "34716848",
      "name": "D. Zaitsev"}]}, {"paperId": "820926337196f774603a236deec2d99901f790c6",
      "externalIds": {"ArXiv": "2303.13248", "DBLP": "journals/corr/abs-2303-13248",
      "DOI": "10.48550/arXiv.2303.13248", "CorpusId": 257687501}, "corpusId": 257687501,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/820926337196f774603a236deec2d99901f790c6",
      "title": "Numerical Bifurcation Analysis of Turing and Symmetry Broken Patterns
      of a Vegetation PDE Model", "abstract": "We study the mechanisms of pattern
      formation for vegetation dynamics in water-limited regions. Our analysis is
      based on a set of two partial differential equations (PDEs) of reaction-diffusion
      type for the biomass and water and one ordinary differential equation (ODE)
      describing the dependence of the toxicity on the biomass. We perform a linear
      stability analysis in the one-dimensional finite space, we derive analytically
      the conditions for the appearance of Turing instability that gives rise to spatio-temporal
      patterns emanating from the homogeneous solution, and provide its dependence
      with respect to the size of the domain. Furthermore, we perform a numerical
      bifurcation analysis in order to study the pattern formation of the inhomogeneous
      solution, with respect to the precipitation rate, thus analyzing the stability
      and symmetry properties of the emanating patterns. Based on the numerical bifurcation
      analysis, we have found new patterns, which form due to the onset of secondary
      bifurcations from the primary Turing instability, thus giving rise to a multistability
      of asymmetric solutions.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      38, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics",
      "Physics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Physics", "source":
      "external"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-03-23", "journal": {"name": "ArXiv",
      "volume": "abs/2303.13248"}, "authors": [{"authorId": "2234681", "name": "K.
      Spiliotis"}, {"authorId": "145080345", "name": "L. Russo"}, {"authorId": "2074336",
      "name": "F. Giannino"}, {"authorId": "1715996", "name": "C. Siettos"}]}, {"paperId":
      "dc9f9ea229b5e515e89714a538f9f449c8afd1d0", "externalIds": {"DBLP": "journals/corr/abs-2307-08315",
      "ArXiv": "2307.08315", "DOI": "10.48550/arXiv.2307.08315", "CorpusId": 259937735},
      "corpusId": 259937735, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/dc9f9ea229b5e515e89714a538f9f449c8afd1d0",
      "title": "IterLara: A Turing Complete Algebra for Big Data, AI, Scientific Computing,
      and Database", "abstract": "\\textsc{Lara} is a key-value algebra that aims
      at unifying linear and relational algebra with three types of operation abstraction.
      The study of \\textsc{Lara}''s expressive ability reports that it can represent
      relational algebra and most linear algebra operations. However, several essential
      computations, such as matrix inversion and determinant, cannot be expressed
      in \\textsc{Lara}. \\textsc{Lara} cannot represent global and iterative computation,
      either. This article proposes \\textsc{IterLara}, extending \\textsc{Lara} with
      iterative operators, to provide an algebraic model that unifies operations in
      general-purpose computing, like big data, AI, scientific computing, and database.
      We study the expressive ability of \\textsc{Lara} and \\textsc{IterLara} and
      prove that \\textsc{IterLara} with aggregation functions can represent matrix
      inversion, determinant. Besides, we demonstrate that \\textsc{IterLara} with
      no limitation of function utility is Turing complete. We also propose the Operation
      Count (OP) as a metric of computation amount for \\textsc{IterLara} and ensure
      that the OP metric is in accordance with the existing computation metrics.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 15, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-07-17", "journal": {"name": "ArXiv", "volume": "abs/2307.08315"}, "authors":
      [{"authorId": "2108578660", "name": "Hongxiao Li"}, {"authorId": "46874006",
      "name": "Wanling Gao"}, {"authorId": "36547165", "name": "Lei Wang"}, {"authorId":
      "2062319", "name": "Jianfeng Zhan"}]}, {"paperId": "0ec10eb38a72f60cac856d3341227a1a6be4cd98",
      "externalIds": {"ArXiv": "2305.14252", "DBLP": "journals/corr/abs-2305-14252",
      "DOI": "10.48550/arXiv.2305.14252", "CorpusId": 258841718}, "corpusId": 258841718,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/0ec10eb38a72f60cac856d3341227a1a6be4cd98",
      "title": "Quantum Kolmogorov complexity and quantum correlations in deterministic-control
      quantum Turing machines", "abstract": "This work presents a study of Kolmogorov
      complexity for general quantum states from the perspective of deterministic-control
      quantum Turing Machines (dcq-TM). We extend the dcq-TM model to incorporate
      mixed state inputs and outputs, and define dcq-computable states as those that
      can be approximated by a dcq-TM. Moreover, we introduce (conditional) Kolmogorov
      complexity of quantum states and use it to study three particular aspects of
      the algorithmic information contained in a quantum state: a comparison of the
      information in a quantum state with that of its classical representation as
      an array of real numbers, an exploration of the limits of quantum state copying
      in the context of algorithmic complexity, and study of the complexity of correlations
      in quantum systems, resulting in a correlation-aware definition for algorithmic
      mutual information that satisfies symmetry of information property.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 36, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Physics",
      "Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Physics",
      "source": "external"}, {"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-05-23", "journal": {"name": "ArXiv", "volume": "abs/2305.14252"}, "authors":
      [{"authorId": "145451615", "name": "M. Lemus"}, {"authorId": "103308544", "name":
      "Ricardo Faleiro"}, {"authorId": "144372606", "name": "P. Mateus"}, {"authorId":
      "2218427588", "name": "Nikola Paunkovi''c"}, {"authorId": "151498130", "name":
      "Andr\u00e9 Souto"}]}, {"paperId": "02f5aa2fb0f8a956a2acbb7e457d78d416ebf9ad",
      "externalIds": {"DBLP": "journals/corr/abs-2306-05582", "ArXiv": "2306.05582",
      "DOI": "10.48550/arXiv.2306.05582", "CorpusId": 259129336}, "corpusId": 259129336,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/02f5aa2fb0f8a956a2acbb7e457d78d416ebf9ad",
      "title": "A newborn embodied Turing test for view-invariant object recognition",
      "abstract": "Recent progress in artificial intelligence has renewed interest
      in building machines that learn like animals. Almost all of the work comparing
      learning across biological and artificial systems comes from studies where animals
      and machines received different training data, obscuring whether differences
      between animals and machines emerged from differences in learning mechanisms
      versus training data. We present an experimental approach-a\"newborn embodied
      Turing Test\"-that allows newborn animals and machines to be raised in the same
      environments and tested with the same tasks, permitting direct comparison of
      their learning abilities. To make this platform, we first collected controlled-rearing
      data from newborn chicks, then performed\"digital twin\"experiments in which
      machines were raised in virtual environments that mimicked the rearing conditions
      of the chicks. We found that (1) machines (deep reinforcement learning agents
      with intrinsic motivation) can spontaneously develop visually guided preference
      behavior, akin to imprinting in newborn chicks, and (2) machines are still far
      from newborn-level performance on object recognition tasks. Almost all of the
      chicks developed view-invariant object recognition, whereas the machines tended
      to develop view-dependent recognition. The learning outcomes were also far more
      constrained in the chicks versus machines. Ultimately, we anticipate that this
      approach will help researchers develop embodied AI systems that learn like newborn
      animals.", "venue": "arXiv.org", "year": 2023, "referenceCount": 24, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Biology"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Biology", "source":
      "external"}, {"category": "Psychology", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-06-08", "journal": {"name": "ArXiv",
      "volume": "abs/2306.05582"}, "authors": [{"authorId": "2111880202", "name":
      "Denizhan Pak"}, {"authorId": "2109484738", "name": "Donsuk Lee"}, {"authorId":
      "145208012", "name": "Samantha M. W. Wood"}, {"authorId": "2237822", "name":
      "Justin N. Wood"}]}, {"paperId": "64660987ee2a526ab343f2df7310bf03a0576903",
      "externalIds": {"DBLP": "journals/corr/abs-2307-11747", "ArXiv": "2307.11747",
      "DOI": "10.48550/arXiv.2307.11747", "CorpusId": 260091638}, "corpusId": 260091638,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/64660987ee2a526ab343f2df7310bf03a0576903",
      "title": "Simulation of Turing machines with analytic discrete ODEs: FPTIME
      and FPSPACE over the reals characterised with discrete ordinary differential
      equations", "abstract": "We prove that functions over the reals computable in
      polynomial time can be characterised using discrete ordinary differential equations
      (ODE), also known as finite differences. We also provide a characterisation
      of functions computable in polynomial space over the reals. In particular, this
      covers space complexity, while existing characterisations were only able to
      cover time complexity, and were restricted to functions over the integers. We
      prove furthermore that no artificial sign or test function is needed even for
      time complexity. At a technical level, this is obtained by proving that Turing
      machines can be simulated with analytic discrete ordinary differential equations.
      We believe this result opens the way to many applications, as it opens the possibility
      of programming with ODEs, with an underlying well-understood time and space
      complexity.", "venue": "arXiv.org", "year": 2023, "referenceCount": 29, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-07-21", "journal": {"name": "ArXiv",
      "volume": "abs/2307.11747"}, "authors": [{"authorId": "2113388525", "name":
      "Manon Blanc"}, {"authorId": "1706341", "name": "Olivier Bournez"}]}, {"paperId":
      "842518e260c406f8f17d04a4fcb64a04050b67cd", "externalIds": {"DBLP": "journals/corr/abs-2308-02308",
      "ArXiv": "2308.02308", "DOI": "10.48550/arXiv.2308.02308", "CorpusId": 260611559},
      "corpusId": 260611559, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/842518e260c406f8f17d04a4fcb64a04050b67cd",
      "title": "A Thermodynamically Universal Turing Machine", "abstract": "Expanding
      upon the widely recognized notion of mathematical universality in Turing machines,
      a concept of thermodynamic universality in Turing machines is introduced. Under
      the physical Church-Turing thesis, the existence of a thermodynamically universal
      Turing machine (TUTM) is demonstrated. A TUTM not only has the capability to
      simulate the input-output behavior of any given Turing machine but also replicate
      the heat production of that machine up to an additive constant. The finding
      shows that the hypothesis that the physical world is simulated by Turing machines
      may not be completely absurd.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      8, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Physics",
      "source": "external"}, {"category": "Materials Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-07-06", "journal":
      {"name": "ArXiv", "volume": "abs/2308.02308"}, "authors": [{"authorId": "2228810671",
      "name": "Jihai Zhu"}]}, {"paperId": "515c5f0f2eb98f273dd6c262349260d1f6e2c740",
      "externalIds": {"DBLP": "journals/corr/abs-2307-02241", "ArXiv": "2307.02241",
      "DOI": "10.48550/arXiv.2307.02241", "CorpusId": 259341761}, "corpusId": 259341761,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/515c5f0f2eb98f273dd6c262349260d1f6e2c740",
      "title": "Approximate Turing kernelization and lower bounds for domination problems",
      "abstract": "An $\\alpha$-approximate polynomial Turing kernelization is a polynomial-time
      algorithm that computes an $(\\alpha c)$-approximate solution for a parameterized
      optimization problem when given access to an oracle that can compute $c$-approximate
      solutions to instances with size bounded by a polynomial in the parameter. Hols
      et al. [ESA 2020] showed that a wide array of graph problems admit a $(1+\\varepsilon)$-approximate
      polynomial Turing kernelization when parameterized by the treewidth of the graph
      and left open whether Dominating Set also admits such a kernelization. We show
      that Dominating Set and several related problems parameterized by treewidth
      do not admit constant-factor approximate polynomial Turing kernelizations, even
      with respect to the much larger parameter vertex cover number, under certain
      reasonable complexity assumptions.On the positive side, we show that all of
      them do have a $(1+\\varepsilon)$-approximate polynomial Turing kernelization
      for every $\\varepsilon>0$ for the joint parameterization by treewidth and maximum
      degree, a parameter which generalizes cutwidth, for example.", "venue": "arXiv.org",
      "year": 2023, "referenceCount": 31, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-07-05", "journal": {"name": "ArXiv", "volume": "abs/2307.02241"}, "authors":
      [{"authorId": "1692122", "name": "Stefan Kratsch"}, {"authorId": "32123939",
      "name": "Pascal Kunz"}]}, {"paperId": "f7c31ed51a8a8a0156b5a129168d058bab0e8022",
      "externalIds": {"DBLP": "journals/corr/abs-2307-05285", "ArXiv": "2307.05285",
      "DOI": "10.48550/arXiv.2307.05285", "CorpusId": 259766465}, "corpusId": 259766465,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/f7c31ed51a8a8a0156b5a129168d058bab0e8022",
      "title": "Turing patterns in a 3D morpho-chemical bulk-surface reaction-diffusion
      system for battery modeling", "abstract": "In this paper we introduce a bulk-surface
      reaction-diffusion (BSRD) model in three space dimensions that extends the DIB
      morphochemical model to account for the electrolyte contribution in the application,
      in order to study structure formation during discharge-charge processes in batteries.
      Here we propose to approximate the model by the Bulk-Surface Virtual Element
      Method on a tailor-made mesh that proves to be competitive with fast bespoke
      methods for PDEs on Cartesian grids. We present a selection of numerical simulations
      that accurately match the classical morphologies found in experiments. Finally,
      we compare the Turing patterns obtained by the coupled 3D BS-DIB model with
      those obtained with the original 2D version.", "venue": "arXiv.org", "year":
      2023, "referenceCount": 20, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "external"}, {"category":
      "Materials Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-07-11", "journal": {"name": "ArXiv", "volume": "abs/2307.05285"},
      "authors": [{"authorId": "38056322", "name": "Massimo Frittelli"}, {"authorId":
      "1914459", "name": "I. Sgura"}, {"authorId": "2127715407", "name": "B. Bozzini"}]},
      {"paperId": "e05c643afd4a2c1889b7f7e3f90ce712026e1d4c", "externalIds": {"DBLP":
      "journals/corr/abs-2305-15677", "ArXiv": "2305.15677", "DOI": "10.48550/arXiv.2305.15677",
      "CorpusId": 258887782}, "corpusId": 258887782, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/e05c643afd4a2c1889b7f7e3f90ce712026e1d4c",
      "title": "Nonlinear Bipartite Output Regulation with Application to Turing Pattern",
      "abstract": "In this paper, a bipartite output regulation problem is solved
      for a class of nonlinear multi-agent systems subject to static signed communication
      networks. A nonlinear distributed observer is proposed for a nonlinear exosystem
      with cooperation-competition interactions to address the problem. Sufficient
      conditions are provided to guarantee its existence and stability. The exponential
      stability of the observer is established. As a practical application, a leader-following
      bipartite consensus problem is solved for a class of nonlinear multi-agent systems
      based on the observer. Finally, a network of multiple pendulum systems is treated
      to support the feasibility of the proposed design. The possible application
      of the approach to generate specific Turing patterns is also presented.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 41, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Mathematics", "Engineering", "Physics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Engineering", "source": "external"}, {"category":
      "Physics", "source": "external"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-05-25", "journal":
      {"name": "ArXiv", "volume": "abs/2305.15677"}, "authors": [{"authorId": "2113984966",
      "name": "Dong Liang"}, {"authorId": "144449892", "name": "M. Guay"}, {"authorId":
      "50694870", "name": "Shimin Wang"}]}, {"paperId": "b2880b21f0c409ab1d602e18fbacbdb9737e522b",
      "externalIds": {"ArXiv": "2303.06512", "DBLP": "journals/corr/abs-2303-06512",
      "DOI": "10.48550/arXiv.2303.06512", "CorpusId": 257496820}, "corpusId": 257496820,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/b2880b21f0c409ab1d602e18fbacbdb9737e522b",
      "title": "Piecewise DMD for oscillatory and Turing spatio-temporal dynamics",
      "abstract": "Dynamic Mode Decomposition (DMD) is an equation-free method that
      aims at reconstructing the best linear fit from temporal datasets. In this paper,
      we show that DMD does not provide accurate approximation for datasets describing
      oscillatory dynamics, like spiral waves and relaxation oscillations, or spatio-temporal
      Turing instability. Inspired from the classical\"divide and conquer\"approach,
      we propose a piecewise version of DMD (pDMD) to overcome this problem. The main
      idea is to split the original dataset in N submatrices and then apply the exact
      (randomized) DMD method in each subset of the obtained partition. We describe
      the pDMD algorithm in detail and we introduce some error indicators to evaluate
      its performance when N is increased. Numerical experiments show that very accurate
      reconstructions are obtained by pDMD for datasets arising from time snapshots
      of some reaction-diffusion PDE systems, like the FitzHugh-Nagumo model, the
      lambda-omega system and the DIB morpho-chemical system for battery modeling.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 29, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-03-11", "journal": {"name": "ArXiv",
      "volume": "abs/2303.06512"}, "authors": [{"authorId": "47766762", "name": "A.
      Alla"}, {"authorId": "1471727847", "name": "A. Monti"}, {"authorId": "1914459",
      "name": "I. Sgura"}]}, {"paperId": "e64959bee8eb02ce5f224e80b8e99282c576bcb3",
      "externalIds": {"DBLP": "journals/corr/abs-2308-14236", "DOI": "10.48550/arXiv.2308.14236",
      "CorpusId": 261432178}, "corpusId": 261432178, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/e64959bee8eb02ce5f224e80b8e99282c576bcb3",
      "title": "A conservative Turing complete S4 flow", "abstract": null, "venue":
      "arXiv.org", "year": 2023, "referenceCount": 0, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
      {"name": "ArXiv", "volume": "abs/2308.14236"}, "authors": [{"authorId": "1388712122",
      "name": "P. Su\u00e1rez-Serrato"}]}, {"paperId": "1fab97516e0545cbe879739c1228f286f8c4b9fe",
      "externalIds": {"ArXiv": "2005.09280", "DBLP": "journals/corr/abs-2005-09280",
      "MAG": "3027638931", "CorpusId": 218684798}, "corpusId": 218684798, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/1fab97516e0545cbe879739c1228f286f8c4b9fe",
      "title": "Controlled Language and Baby Turing Test for General Conversational
      Intelligence", "abstract": "General conversational intelligence appears to be
      an important part of artificial general intelligence. Respectively, it requires
      accessible measures of the intelligence quality and controllable ways of its
      achievement, ideally - having the linguistic and semantic models represented
      in a reasonable way. Our work is suggesting to use Baby Turing Test approach
      to extend the classic Turing Test for conversational intelligence and controlled
      language based on semantic graph representation extensible for arbitrary subject
      domain. We describe how the two can be used together to build a general-purpose
      conversational system such as an intelligent assistant for online media and
      social network data processing.", "venue": "arXiv.org", "year": 2020, "referenceCount":
      21, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2020-05-19", "journal": {"name": "ArXiv", "volume": "abs/2005.09280"},
      "authors": [{"authorId": "1847471", "name": "A. Kolonin"}]}, {"paperId": "9b15d747d8341cc12e74a9dc539f93d57842cf21",
      "externalIds": {"MAG": "3036645521", "DBLP": "journals/corr/abs-2006-11373",
      "ArXiv": "2006.11373", "DOI": "10.2139/ssrn.3624282", "CorpusId": 219966912},
      "corpusId": 219966912, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/9b15d747d8341cc12e74a9dc539f93d57842cf21",
      "title": "Deceiving Computers in Reverse Turing Test through Deep Learning",
      "abstract": "It is increasingly becoming difficult for human beings to work
      on their day to day life without going through the process of reverse Turing
      test, where the Computers tests the users to be humans or not. Almost every
      website and service providers today have the process of checking whether their
      website is being crawled or not by automated bots which could extract valuable
      information from their site. In the process the bots are getting more intelligent
      by the use of Deep Learning techniques to decipher those tests and gain unwanted
      automated access to data while create nuisance by posting spam. Humans spend
      a considerable amount of time almost every day when trying to decipher CAPTCHAs.
      The aim of this investigation is to check whether the use of a subset of commonly
      used CAPTCHAs, known as the text CAPTCHA is a reliable process for verifying
      their human customers. We mainly focused on the preprocessing step for every
      CAPTCHA which converts them in binary intensity and removes the confusion as
      much as possible and developed various models to correctly label as many CAPTCHAs
      as possible. We also suggested some ways to improve the process of verifying
      the humans which makes it easy for humans to solve the existing CAPTCHAs and
      difficult for bots to do the same.", "venue": "arXiv.org", "year": 2020, "referenceCount":
      14, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "http://arxiv.org/pdf/2006.11373", "status": "GREEN"},
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2020-06-01", "journal": {"name": "EngRN: Electronic"}, "authors": [{"authorId":
      "108673467", "name": "Jimut Bahan Pal"}]}, {"paperId": "59fbd590e09c7b4dd18373e4990e7254cef984b7",
      "externalIds": {"DBLP": "journals/corr/abs-2001-07592", "MAG": "3003287862",
      "CorpusId": 208147652}, "corpusId": 208147652, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/59fbd590e09c7b4dd18373e4990e7254cef984b7",
      "title": "Turing analogues of G\u00f6del statements and computability of intelligence",
      "abstract": "We show that there is a mathematical obstruction to complete Turing
      computability of intelligence. This obstruction can be circumvented only if
      human reasoning is fundamentally unsound. The most compelling original argument
      for existence of such an obstruction was proposed by Penrose, however G\\\"odel,
      Turing and Lucas have also proposed such arguments. We first partially reformulate
      the argument of Penrose. In this formulation we argue that his argument works
      up to possibility of construction of a certain G\\\"odel statement. We then
      completely re-frame the argument in the language of Turing machines, and by
      partially defining our subject just enough, we show that a certain analogue
      of a G\\\"odel statement, or a G\\\"odel string as we call it in the language
      of Turing machines, can be readily constructed directly, without appeal to the
      G\\\"odel incompleteness theorem, and thus removing the final objection.", "venue":
      "arXiv.org", "year": 2020, "referenceCount": 25, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category":
      "Philosophy", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2020-01-21", "journal": {"name": "ArXiv", "volume": "abs/2001.07592"},
      "authors": [{"authorId": "2042592", "name": "Y. Savelyev"}]}, {"paperId": "fb1c54422404d40b0509b4f13c0a25741cbf7dc1",
      "externalIds": {"ArXiv": "2010.14753", "DBLP": "journals/corr/abs-2010-14753",
      "MAG": "3096363261", "CorpusId": 225094536}, "corpusId": 225094536, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/fb1c54422404d40b0509b4f13c0a25741cbf7dc1",
      "title": "A short note on the decision tree based neural turing machine", "abstract":
      "Turing machine and decision tree have developed independently for a long time.
      With the recent development of differentiable models, there is an intersection
      between them. Neural turing machine(NTM) opens door for the memory network.
      It use differentiable attention mechanism to read/write external memory bank.
      Differentiable forest brings differentiable properties to classical decision
      tree. In this short note, we show the deep connection between these two models.
      That is: differentiable forest is a special case of NTM. Differentiable forest
      is actually decision tree based neural turing machine. Based on this deep connection,
      we propose a response augmented differential forest (RaDF). The controller of
      RaDF is differentiable forest, the external memory of RaDF are response vectors
      which would be read/write by leaf nodes.", "venue": "arXiv.org", "year": 2020,
      "referenceCount": 28, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2020-10-27", "journal": {"name": "ArXiv", "volume": "abs/2010.14753"},
      "authors": [{"authorId": "2109316597", "name": "Yingshi Chen"}]}, {"paperId":
      "2c9bc37ffb555ca327aeebf769f2436fac1685d2", "externalIds": {"ArXiv": "2008.04640",
      "DBLP": "journals/corr/abs-2008-04640", "MAG": "3048401942", "CorpusId": 221095748},
      "corpusId": 221095748, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/2c9bc37ffb555ca327aeebf769f2436fac1685d2",
      "title": "High-concurrency Custom-build Relational Database System''s design
      and SQL parser design based on Turing-complete automata", "abstract": "Database
      system is an indispensable part of software projects. It plays an important
      role in data organization and storage. Its performance and efficiency are directly
      related to the performance of software. Nowadays, we have many general relational
      database systems that can be used in our projects, such as SQL Server, MySQL,
      Oracle, etc. It is undeniable that in most cases, we can easily use these database
      systems to complete our projects, but considering the generality, the general
      database systems often can''t play the ultimate speed and fully adapt to our
      projects. In very few projects, we will need to design a database system that
      fully adapt to our projects and have a high efficiency and concurrency. Therefore,
      it is very important to consider a feasible solution of designing a database
      system (We only consider the relational database system here). Meanwhile, for
      a database system, SQL interpretation and execution module is necessary. According
      to the theory of formal language and automata, the realization of this module
      can be completed by automata. In our experiment, we made the following contributions:
      1) We designed a small relational database, and used the database to complete
      a highly concurrent student course selection system. 2) We design a general
      automaton module, which can complete the operation from parsing to execution.
      The using of strategy model and event driven design scheme is used and some
      improvement on general automata, for example a memory like structure is added
      to automata to make it better to store context. All these make the automata
      model can be used in a variety of occasions, not only the parsing and execution
      of SQL statements.", "venue": "arXiv.org", "year": 2020, "referenceCount": 0,
      "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2020-08-11", "journal": {"name": "ArXiv", "volume": "abs/2008.04640"}, "authors":
      [{"authorId": "2217789", "name": "Wanhong Huang"}]}, {"paperId": "f10e071292d593fef939e6ef4a59baf0bb3a6c2b",
      "externalIds": {"ArXiv": "1505.00521", "MAG": "2125308790", "DBLP": "journals/corr/ZarembaS15",
      "CorpusId": 16228924}, "corpusId": 16228924, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/f10e071292d593fef939e6ef4a59baf0bb3a6c2b",
      "title": "Reinforcement Learning Neural Turing Machines", "abstract": "The expressive
      power of a machine learning model is closely related to the number of sequential
      computational steps it can learn. For example, Deep Neural Networks have been
      more successful than shallow networks because they can perform a greater number
      of sequential computational steps (each highly parallel). The Neural Turing
      Machine (NTM) [8] is a model that can compactly express an even greater number
      of sequential computational steps, so it is even more powerful than a DNN. Its
      memory addressing operations are designed to be differentiable; thus the NTM
      can be trained with backpropagation. While differentiable memory is relatively
      easy to implement and train, it necessitates accessing the entire memory content
      at each computational step. This makes it difficult to implement a fast NTM.
      In this work, we use the Re inforce algorithm to learn where to access the memory,
      while using backpropagation to learn what to write to the memory. We call this
      model the RL-NTM. Reinforce allows our model to access a constant number of
      memory cells at each computational step, so its implementation can be faster.
      The RL-NTM is the first mo del that can, in principle, learn programs of unbounded
      running time. We successfully trained the RL-NTM to solve a number of algorithmic
      tasks that are simpler than the ones solvable by the fully differentiable NTM.
      As the RL-NTM is a fairly intricate model, we needed a method for verifying
      the correctness of our implementation. To do so, we developed a simple technique
      for numerically checking arbitrary implementations of models that use Reinforce,
      which may be of independent interest.", "venue": "arXiv.org", "year": 2015,
      "referenceCount": 19, "citationCount": 167, "influentialCitationCount": 9, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2015-05-04", "journal": {"name": "ArXiv", "volume": "abs/1505.00521"},
      "authors": [{"authorId": "2563432", "name": "Wojciech Zaremba"}, {"authorId":
      "1701686", "name": "Ilya Sutskever"}]}, {"paperId": "b4240aecb20ba5f7575c0d68999337f7a8d811c7",
      "externalIds": {"MAG": "2935969996", "DBLP": "journals/corr/abs-1904-05061",
      "CorpusId": 131774001}, "corpusId": 131774001, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/b4240aecb20ba5f7575c0d68999337f7a8d811c7",
      "title": "A review on Neural Turing Machine", "abstract": "One of the major
      objectives of Artificial Intelligence is to design learning algorithms that
      are executed on a general purposes computational machines such as human brain.
      Neural Turing Machine (NTM) is a step towards realizing such a computational
      machine. The attempt is made here to run a systematic review on Neural Turing
      Machine. First, the mind-map and taxonomy of machine learning, neural networks,
      and Turing machine are introduced. Next, NTM is inspected in terms of concepts,
      structure, variety of versions, implemented tasks, comparisons, etc. Finally,
      the paper discusses on issues and ends up with several future works.", "venue":
      "arXiv.org", "year": 2019, "referenceCount": 67, "citationCount": 3, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Review"], "publicationDate": "2019-04-10", "journal": {"name":
      "ArXiv", "volume": "abs/1904.05061"}, "authors": [{"authorId": "123556355",
      "name": "Soroor Malekmohamadi Faradonbe"}, {"authorId": "3084734", "name": "Faramarz
      Safi Esfahani"}]}, {"paperId": "20b7ccf5b76d876973d6ba82c8fa3a1b9b16aa34", "externalIds":
      {"DBLP": "journals/corr/abs-1903-07837", "ArXiv": "1903.07837", "MAG": "2922218648",
      "CorpusId": 83458758}, "corpusId": 83458758, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/20b7ccf5b76d876973d6ba82c8fa3a1b9b16aa34",
      "title": "Turing-Completeness of Dynamics in Abstract Persuasion Argumentation",
      "abstract": "Abstract Persuasion Argumentation (APA) is a dynamic argumentation
      formalism that extends Dung argumentation with persuasion relations. In this
      work, we show through two-counter Minsky machine encoding that APA dynamics
      is Turing-complete.", "venue": "arXiv.org", "year": 2019, "referenceCount":
      3, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Philosophy",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-03-19", "journal": {"name": "ArXiv", "volume": "abs/1903.07837"}, "authors":
      [{"authorId": "2104370", "name": "Ryuta Arisaka"}]}, {"paperId": "e4d23379621a978fb51c4ddd727cda1da8dc428c",
      "externalIds": {"ArXiv": "1904.02478", "MAG": "2930954426", "DBLP": "journals/corr/abs-1904-02478",
      "CorpusId": 102353399}, "corpusId": 102353399, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/e4d23379621a978fb51c4ddd727cda1da8dc428c",
      "title": "Learning Numeracy: Binary Arithmetic with Neural Turing Machines",
      "abstract": "One of the main problems encountered so far with recurrent neural
      networks is that they struggle to retain long-time information dependencies
      in their recurrent connections. Neural Turing Machines (NTMs) attempt to mitigate
      this issue by providing the neural network with an external portion of memory,
      in which information can be stored and manipulated later on. The whole mechanism
      is differentiable end-to-end, allowing the network to learn how to utilise this
      long-term memory via stochastic gradient descent. This allows NTMs to infer
      simple algorithms directly from data sequences. Nonetheless, the model can be
      hard to train due to a large number of parameters and interacting components
      and little related work is present. In this work we use NTMs to learn and generalise
      two arithmetical tasks: binary addition and multiplication. These tasks are
      two fundamental algorithmic examples in computer science, and are a lot more
      challenging than the previously explored ones, with which we aim to shed some
      light on the real capabilities on this neural model.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 30, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-04-04", "journal": {"name": "ArXiv",
      "volume": "abs/1904.02478"}, "authors": [{"authorId": "8755079", "name": "Jacopo
      Castellini"}]}, {"paperId": "839e30cc776a999a1a6da72621d52d3a556ad1c7", "externalIds":
      {"MAG": "2911899023", "DBLP": "journals/corr/abs-1901-06613", "ArXiv": "1901.06613",
      "CorpusId": 58981345}, "corpusId": 58981345, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/839e30cc776a999a1a6da72621d52d3a556ad1c7",
      "title": "Beyond Turing: Intelligent Agents Centered on the User", "abstract":
      "Most research on intelligent agents centers on the agent and not on the user.
      We look at the origins of agent-centric research for slot-filling, gaming and
      chatbot agents. We then argue that it is important to concentrate more on the
      user. After reviewing relevant literature, some approaches for creating and
      assessing user-centric systems are proposed.", "venue": "arXiv.org", "year":
      2019, "referenceCount": 42, "citationCount": 10, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Review"], "publicationDate": "2019-01-20", "journal": {"name":
      "ArXiv", "volume": "abs/1901.06613"}, "authors": [{"authorId": "1716325", "name":
      "M. Esk\u00e9nazi"}, {"authorId": "32251567", "name": "Shikib Mehri"}, {"authorId":
      "66879943", "name": "E. Razumovskaia"}, {"authorId": "8200875", "name": "Tiancheng
      Zhao"}]}, {"paperId": "6a10ce04a28d2b34c102133fcf94ff299d1e1780", "externalIds":
      {"ArXiv": "1905.12734", "DBLP": "journals/corr/abs-1905-12734", "MAG": "2947997817",
      "CorpusId": 170078578}, "corpusId": 170078578, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/6a10ce04a28d2b34c102133fcf94ff299d1e1780",
      "title": "Sub-Turing Islands in the Wild", "abstract": "Recently, there has
      been growing debate as to whether or not static analysis can be truly sound.
      In spite of this concern, research on techniques seeking to at least partially
      answer undecidable questions has a long history. However, little attention has
      been given to the more empirical question of how often an exact solution might
      be given to a question despite the question being, at least in theory, undecidable.
      This paper investigates this issue by exploring sub-Turing islands -- regions
      of code for which a question of interest is decidable. We define such islands
      and then consider how to identify them. We implemented Cook, a prototype for
      finding sub-Turing islands and applied it to a corpus of 1100 Android applications,
      containing over 2 million methods. Results reveal that 55\\% of the all methods
      are sub-Turing. Our results also provide empirical, scientific evidence for
      the scalability of sub-Turing island identification. Sub-Turing identification
      has many downstream applications, because islands are so amenable to static
      analysis. We illustrate two downstream uses of the analysis. In the first, we
      found that over 37\\% of the verification conditions associated with runtime
      exceptions fell within sub-Turing islands and thus are statically decidable.
      A second use of our analysis is during code review where it provides guidance
      to developers. The sub-Turing islands from our study turns out to contain significantly
      fewer bugs than `theswamp'' (non sub-Turing methods). The greater bug density
      in the swamp is unsurprising; the fact that bugs remain prevalent in islands
      is, however, surprising: these are bugs whose repair can be fully automated.",
      "venue": "arXiv.org", "year": 2019, "referenceCount": 72, "citationCount": 1,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Review"], "publicationDate":
      "2019-05-29", "journal": {"name": "ArXiv", "volume": "abs/1905.12734"}, "authors":
      [{"authorId": "1757975", "name": "Earl T. Barr"}, {"authorId": "3408880", "name":
      "D. Binkley"}, {"authorId": "145836176", "name": "M. Harman"}, {"authorId":
      "31433415", "name": "M. Seghir"}]}, {"paperId": "10234b876b1e0cec42db32f560f8a8cbae7d40cf",
      "externalIds": {"MAG": "2913719695", "DBLP": "journals/corr/abs-1902-00975",
      "ArXiv": "1902.00975", "CorpusId": 59599703}, "corpusId": 59599703, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/10234b876b1e0cec42db32f560f8a8cbae7d40cf",
      "title": "Some Remarks on Real-Time Turing Machines", "abstract": "The power
      of real-time Turing machines using sublinear space is investigated. In contrast
      to a claim appearing in the literature, such machines can accept non-regular
      languages, even if working in deterministic mode. While maintaining a standard
      binary counter appears to be impossible in real-time, we present a guess and
      check approach that yields a binary representation of the input length. Based
      on this technique, we show that unary encodings of languages accepted in exponential
      time can be recognized by nondeterministic real-time Turing machines.", "venue":
      "arXiv.org", "year": 2019, "referenceCount": 10, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-02-03", "journal": {"name": "ArXiv", "volume": "abs/1902.00975"},
      "authors": [{"authorId": "144511065", "name": "H. Petersen"}]}, {"paperId":
      "154e736e2ddbcd71e090403e9b28b26d52ec0d55", "externalIds": {"MAG": "2949710727",
      "DBLP": "journals/corr/abs-1906-05833", "CorpusId": 189762070}, "corpusId":
      189762070, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/154e736e2ddbcd71e090403e9b28b26d52ec0d55",
      "title": "There is no general AI: Why Turing machines cannot pass the Turing
      test", "abstract": "Since 1950, when Alan Turing proposed what has since come
      to be called the Turing test, the ability of a machine to pass this test has
      established itself as the primary hallmark of general AI. To pass the test,
      a machine would have to be able to engage in dialogue in such a way that a human
      interrogator could not distinguish its behaviour from that of a human being.
      AI researchers have attempted to build machines that could meet this requirement,
      but they have so far failed. To pass the test, a machine would have to meet
      two conditions: (i) react appropriately to the variance in human dialogue and
      (ii) display a human-like personality and intentions. We argue, first, that
      it is for mathematical reasons impossible to program a machine which can master
      the enormously complex and constantly evolving pattern of variance which human
      dialogues contain. And second, that we do not know how to make machines that
      possess personality and intentions of the sort we find in humans. Since a Turing
      machine cannot master human dialogue behaviour, we conclude that a Turing machine
      also cannot possess what is called ``general'''' Artificial Intelligence. We
      do, however, acknowledge the potential of Turing machines to master dialogue
      behaviour in highly restricted contexts, where what is called ``narrow'''' AI
      can still be of considerable utility.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 85, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-06-09", "journal": {"name": "ArXiv", "volume": "abs/1906.05833"},
      "authors": [{"authorId": "120743060", "name": "J. Landgrebe"}, {"authorId":
      "2157085550", "name": "B. Smith"}]}, {"paperId": "1335201fb3ed413fa7879d732bc47623c65d2683",
      "externalIds": {"DBLP": "journals/corr/abs-1907-04211", "MAG": "2962211741",
      "ArXiv": "1907.04211", "CorpusId": 195847986}, "corpusId": 195847986, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/1335201fb3ed413fa7879d732bc47623c65d2683",
      "title": "Universal One-Dimensional Cellular Automata Derived for Turing Machines
      and its Dynamical Behaviour", "abstract": "Universality in cellular automata
      theory is a central problem studied and developed from their origins by John
      von Neumann. In this paper, we present an algorithm where any Turing machine
      can be converted to one-dimensional cellular automaton with a 2-linear time
      and display its spatial dynamics. Three particular Turing machines are converted
      in three universal one-dimensional cellular automata, they are: binary sum,
      rule 110 and a universal reversible Turing machine.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 33, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Physics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
      "external"}, {"category": "Physics", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-07-06", "journal": {"name": "ArXiv", "volume": "abs/1907.04211"},
      "authors": [{"authorId": "148090801", "name": "Sergio J. Mart\u00ednez"}, {"authorId":
      "49521580", "name": "Iv\u00e1n M. Mendoza"}, {"authorId": "153753039", "name":
      "G. J. Mart\u00ednez"}, {"authorId": "1726520", "name": "S. Ninagawa"}]}, {"paperId":
      "445dbe5368386e984a019fd4f372950836274cdb", "externalIds": {"DBLP": "journals/corr/abs-1909-02399",
      "ArXiv": "1909.02399", "MAG": "2972179875", "CorpusId": 202538964}, "corpusId":
      202538964, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/445dbe5368386e984a019fd4f372950836274cdb",
      "title": "Reading Comprehension Ability Test-A Turing Test for Reading Comprehension",
      "abstract": "Reading comprehension is an important ability of human intelligence.
      Literacy and numeracy are two most essential foundation for people to succeed
      at study, at work and in life. Reading comprehension ability is a core component
      of literacy. In most of the education systems, developing reading comprehension
      ability is compulsory in the curriculum from year one to year 12. It is an indispensable
      ability in the dissemination of knowledge. With the emerging artificial intelligence,
      computers start to be able to read and understand like people in some context.
      They can even read better than human beings for some tasks, but have little
      clue in other tasks. It will be very beneficial if we can identify the levels
      of machine comprehension ability, which will direct us on the further improvement.
      Turing test is a well-known test of the difference between computer intelligence
      and human intelligence. In order to be able to compare the difference between
      people reading and machines reading, we proposed a test called (reading) Comprehension
      Ability Test (CAT).CAT is similar to Turing test, passing of which means we
      cannot differentiate people from algorithms in term of their comprehension ability.
      CAT has multiple levels showing the different abilities in reading comprehension,
      from identifying basic facts, performing inference, to understanding the intent
      and sentiment.", "venue": "arXiv.org", "year": 2019, "referenceCount": 7, "citationCount":
      1, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Education", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-09-05", "journal":
      {"name": "ArXiv", "volume": "abs/1909.02399"}, "authors": [{"authorId": "50273189",
      "name": "Yuan Miao"}, {"authorId": "2113477918", "name": "Gongqi Lin"}, {"authorId":
      "3371473", "name": "Yidan Hu"}, {"authorId": "1679209", "name": "C. Miao"}]},
      {"paperId": "906ac7584faf8ead6004be4cc5122320c87df59c", "externalIds": {"ArXiv":
      "1607.00036", "DBLP": "journals/corr/GulcehreCCB16", "MAG": "2470713034", "CorpusId":
      1399676}, "corpusId": 1399676, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/906ac7584faf8ead6004be4cc5122320c87df59c",
      "title": "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes",
      "abstract": "We extend neural Turing machine (NTM) model into a dynamic neural
      Turing machine (D-NTM) by introducing a trainable memory addressing scheme.
      This addressing scheme maintains for each memory cell two separate vectors,
      content and address vectors. This allows the D-NTM to learn a wide variety of
      location-based addressing strategies including both linear and nonlinear ones.
      We implement the D-NTM with both continuous, differentiable and discrete, non-differentiable
      read/write mechanisms. We investigate the mechanisms and effects of learning
      to read and write into a memory through experiments on Facebook bAbI tasks using
      both a feedforward and GRUcontroller. The D-NTM is evaluated on a set of Facebook
      bAbI tasks and shown to outperform NTM and LSTM baselines. We have done extensive
      analysis of our model and different variations of NTM on bAbI task. We also
      provide further experimental results on sequential pMNIST, Stanford Natural
      Language Inference, associative recall and copy tasks.", "venue": "arXiv.org",
      "year": 2016, "referenceCount": 52, "citationCount": 57, "influentialCitationCount":
      8, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2016-06-30", "journal": {"name": "ArXiv",
      "volume": "abs/1607.00036"}, "authors": [{"authorId": "1854385", "name": "\u00c7aglar
      G\u00fcl\u00e7ehre"}, {"authorId": "144631588", "name": "A. Chandar"}, {"authorId":
      "1979489", "name": "Kyunghyun Cho"}, {"authorId": "1751762", "name": "Yoshua
      Bengio"}]}, {"paperId": "dda1822872942f658b89e7e1c1ffe08c35e7b290", "externalIds":
      {"MAG": "2759063673", "ArXiv": "1709.08693", "DBLP": "journals/corr/abs-1709-08693",
      "CorpusId": 195346581}, "corpusId": 195346581, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290",
      "title": "Can you fool AI with adversarial examples on a visual Turing test?",
      "abstract": "Deep learning has achieved impressive results in many areas of
      Computer Vision and Natural Language Pro- cessing. Among others, Visual Question
      Answering (VQA), also referred to a visual Turing test, is considered one of
      the most compelling problems, and recent deep learning models have reported
      significant progress in vision and language modeling. Although Artificial Intelligence
      (AI) is getting closer to passing the visual Turing test, at the same time the
      existence of adversarial examples to deep learning systems may hinder the practical
      application of such systems. In this work, we conduct the first extensive study
      on adversarial examples for VQA systems. In particular, we focus on generating
      targeted adversarial examples for a VQA system while the target is considered
      to be a question-answer pair. Our evaluation shows that the success rate of
      whether a targeted adversarial example can be generated is mostly dependent
      on the choice of the target question-answer pair, and less on the choice of
      images to which the question refers. We also report the language prior phenomenon
      of a VQA model, which can explain why targeted adversarial examples are hard
      to generate for some question-answer targets. We also demonstrate that a compositional
      VQA architecture is slightly more resilient to adversarial attacks than a non-compositional
      one. Our study sheds new light on how to build deep vision and language resilient
      models robust against adversarial examples.", "venue": "arXiv.org", "year":
      2017, "referenceCount": 70, "citationCount": 39, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2017-09-25", "journal": {"name": "ArXiv",
      "volume": "abs/1709.08693"}, "authors": [{"authorId": "2108880352", "name":
      "Xiaojun Xu"}, {"authorId": "1425082935", "name": "Xinyun Chen"}, {"authorId":
      "2118484320", "name": "Chang Liu"}, {"authorId": "34721166", "name": "Anna Rohrbach"},
      {"authorId": "1753210", "name": "Trevor Darrell"}, {"authorId": "143711382",
      "name": "D. Song"}]}, {"paperId": "a893430c89cf27e5b6fd9e19e6cee4f2b8d52dbc",
      "externalIds": {"DBLP": "journals/corr/abs-1901-07125", "MAG": "2914561188",
      "ArXiv": "1901.07125", "CorpusId": 58981696}, "corpusId": 58981696, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/a893430c89cf27e5b6fd9e19e6cee4f2b8d52dbc",
      "title": "The Power of One-State Turing Machines", "abstract": "At first glance,
      one-state Turing machines are very weak: the halting problem for them is decidable,
      and, without memory, they cannot even accept a simple one element language such
      as $L = \\{ 1 \\}$ . Nevertheless it has been showed that a one-state Turing
      machine can accept non regular languages. We extend such result and prove that
      they can also recognize non context-free languages, so for some tasks they are
      more powerful than pushdown automata.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 7, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics", "Computer Science"],
      "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-01-22", "journal": {"name": "ArXiv", "volume": "abs/1901.07125"}, "authors":
      [{"authorId": "35048687", "name": "M. D. Biasi"}]}, {"paperId": "13d6471ff8a1d05f5d0c7e7a72603d9769e3ffb4",
      "externalIds": {"ArXiv": "1905.06311", "MAG": "2944980240", "DBLP": "journals/corr/abs-1905-06311",
      "CorpusId": 155093102}, "corpusId": 155093102, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/13d6471ff8a1d05f5d0c7e7a72603d9769e3ffb4",
      "title": "Inquiry of P-reduction in Cook''s 1971 Paper - from Oracle machine
      to Turing machine", "abstract": "In this paper, we inquire the key concept P-reduction
      in Cook''s theorem and reveal that there exists the fallacy of definition in
      P-reduction caused by the disguised displacement of NDTM from Oracle machine
      to Turing machine. The definition or derivation of P-reduction is essentially
      equivalent to Turing''s computability. Whether NP problems might been reduced
      to logical forms (tautology or SAT) or NP problems might been reduced each other,
      they have not been really proven in Cook''s 1971 paper.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 14, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-04-30", "journal": {"name": "ArXiv",
      "volume": "abs/1905.06311"}, "authors": [{"authorId": "2112367844", "name":
      "JianMing Zhou"}, {"authorId": "2116612064", "name": "Yu Li"}]}, {"paperId":
      "2ccd1a446c3e512104a6cfdc6367ec435b803bd9", "externalIds": {"MAG": "2956310154",
      "DBLP": "journals/corr/abs-1907-06432", "ArXiv": "1907.06432", "CorpusId": 196621673},
      "corpusId": 196621673, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/2ccd1a446c3e512104a6cfdc6367ec435b803bd9",
      "title": "A Neural Turing~Machine for Conditional Transition Graph Modeling",
      "abstract": "Graphs are an essential part of many machine learning problems
      such as analysis of parse trees, social networks, knowledge graphs, transportation
      systems, and molecular structures. Applying machine learning in these areas
      typically involves learning the graph structure and the relationship between
      the nodes of the graph. However, learning the graph structure is often complex,
      particularly when the graph is cyclic, and the transitions from one node to
      another are conditioned such as graphs used to represent a finite state machine.
      To solve this problem, we propose to extend the memory based Neural Turing Machine
      (NTM) with two novel additions. We allow for transitions between nodes to be
      influenced by information received from external environments, and we let the
      NTM learn the context of those transitions. We refer to this extension as the
      Conditional Neural Turing Machine (CNTM). \nWe show that the CNTM can infer
      conditional transition graphs by empirically verifiying the model on two data
      sets: a large set of randomly generated graphs, and a graph modeling the information
      retrieval process during certain crisis situations. The results show that the
      CNTM is able to reproduce the paths inside the graph with accuracy ranging from
      82,12% for 10 nodes graphs to 65,25% for 100 nodes graphs.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 25, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-07-15", "journal": {"name": "ArXiv",
      "volume": "abs/1907.06432"}, "authors": [{"authorId": "1840275", "name": "M.
      B. Lazreg"}, {"authorId": "1833672", "name": "M. G. Olsen"}, {"authorId": "2493161",
      "name": "Ole-Christoffer Granmo"}]}, {"paperId": "b6496718fc89f5c096bbb6706bb7d676c599a5f9",
      "externalIds": {"DBLP": "journals/corr/abs-1903-09653", "MAG": "2922737564",
      "ArXiv": "1903.09653", "CorpusId": 85498441}, "corpusId": 85498441, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/b6496718fc89f5c096bbb6706bb7d676c599a5f9",
      "title": "Anti-Turing Machine", "abstract": "The invention of CPU-centric computing
      paradigm was incredible breakthrough of computer science that revolutionized
      our everyday life dramatically. However, the CPU- centric paradigm is based
      on the Turing machine concept and, as a result, expensive and power-hungry data
      transferring between the memory and CPU core is inevitable operation. Anti-Turing
      machine paradigm can be based on two fundamental principles: (1) data-centric
      computing, and (2) decentralized computing. Anti-Turing machine is able to execute
      a special type of programs. The commands of such program have to be addressed
      to the 2D or 3D persistent memory space is able to process data in-place. This
      program should not define the position or structure of data but it has to define
      the goal of data processing activity. Generally speaking, it needs to consider
      the whole memory space like the data transformation space. But the data placement,
      particular algorithm implementation, and strategy of algorithm execution are
      out of scope of the program.", "venue": "arXiv.org", "year": 2019, "referenceCount":
      7, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-03-22", "journal": {"name": "ArXiv", "volume": "abs/1903.09653"},
      "authors": [{"authorId": "35625237", "name": "Viacheslav Dubeyko"}]}, {"paperId":
      "8ff2ed2ac3b5c91261fd1f8b5694b12886aeca95", "externalIds": {"MAG": "2988969040",
      "ArXiv": "1911.05832", "DBLP": "journals/corr/abs-1911-05832", "CorpusId": 208006389},
      "corpusId": 208006389, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/8ff2ed2ac3b5c91261fd1f8b5694b12886aeca95",
      "title": "Inverse design of fluid flow structure with Turing pattern", "abstract":
      "Microchannel reactors are critical in biological plus energy-related applications
      and require meticulous design of hundreds-to-thousands of fluid flow channels.
      Such systems commonly comprise intricate space-filling microstructures to control
      the fluid flow distribution for the reaction process. Traditional flow channel
      design schemes are intuition-based or utilize analytical rule-based optimization
      strategies that are oversimplified for large-scale domains of arbitrary geometry.
      Here, a gradient-based optimization method is proposed, where effective porous
      media and fluid velocity vector design information is exploited and linked to
      explicit microchannel parameterizations. Reaction-diffusion equations are then
      utilized to generate space-filling Turing pattern microchannel flow structures
      from the porous media field. With this computationally efficient and broadly
      applicable technique, precise control of fluid flow distribution is demonstrated
      across large numbers (on the order of hundreds) of microchannels.", "venue":
      "arXiv.org", "year": 2019, "referenceCount": 23, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Engineering", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-11-13", "journal": {"name": "ArXiv",
      "volume": "abs/1911.05832"}, "authors": [{"authorId": "2191712", "name": "E.
      Dede"}, {"authorId": "49454977", "name": "Yuqing Zhou"}, {"authorId": "32554646",
      "name": "T. Nomura"}]}, {"paperId": "575a082dd24730dfc1c4bae27cd6fa0142028050",
      "externalIds": {"ArXiv": "1901.11090", "MAG": "2911479284", "DBLP": "journals/corr/abs-1901-11090",
      "CorpusId": 59523756}, "corpusId": 59523756, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/575a082dd24730dfc1c4bae27cd6fa0142028050",
      "title": "Neuroevolution with Perceptron Turing Machines", "abstract": "We introduce
      the perceptron Turing machine and show how it can be used to create a system
      of neuroevolution. Advantages of this approach include automatic scaling of
      solutions to larger problem sizes, the ability to experiment with hand-coded
      solutions, and an enhanced potential for understanding evolved solutions. Hand-coded
      solutions may be implemented in the low-level language of Turing machines, which
      is the genotype used in neuroevolution, but a high-level language called Lopro
      is introduced to make the job easier.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 8, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-01-30", "journal": {"name": "ArXiv", "volume": "abs/1901.11090"},
      "authors": [{"authorId": "1971021", "name": "D. Landaeta"}]}, {"paperId": "bf3a6bb7afffadb93013844f64bb9c40911325df",
      "externalIds": {"DBLP": "journals/corr/abs-1906-11068", "MAG": "2955389962",
      "ArXiv": "1906.11068", "CorpusId": 195741908}, "corpusId": 195741908, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/bf3a6bb7afffadb93013844f64bb9c40911325df",
      "title": "Turing Test Revisited: A Framework for an Alternative", "abstract":
      "This paper aims to question the suitability of the Turing Test, for testing
      machine intelligence, in the light of advances made in the last 60 years in
      science, medicine, and philosophy of mind. While the main concept of the test
      may seem sound and valid, a detailed analysis of what is required to pass the
      test highlights a significant flow. Once the analysis of the test is presented,
      a systematic approach is followed in analysing what is needed to devise a test
      or tests for intelligent machines. The paper presents a plausible generic framework
      based on categories of factors implied by subjective perception of intelligence.
      An evaluative discussion concludes the paper highlighting some of the unaddressed
      issues within this generic framework.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 37, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-06-26", "journal": {"name": "ArXiv", "volume": "abs/1906.11068"},
      "authors": [{"authorId": "2886506", "name": "A. Ayesh"}]}, {"paperId": "11b3bb83b8e871f75ba08214f9977b5b4a4cd434",
      "externalIds": {"ArXiv": "1908.01994", "DBLP": "journals/corr/abs-1908-01994",
      "MAG": "2966467752", "CorpusId": 199452992}, "corpusId": 199452992, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/11b3bb83b8e871f75ba08214f9977b5b4a4cd434",
      "title": "Comprehensive Fuzzy Turing Machines, An Evolution to the Concept of
      Finite State Machine Control", "abstract": "The Turing machine is an abstract
      concept of a computing device which introduced new models for computation. The
      idea of Fuzzy algorithms defined by Zadeh and Lee was followed by introducing
      Fuzzy Turing Machine (FTM) to create a platform for a new fuzzy computation
      model. Then, in his investigations on its computational power, Wiedermann showed
      that FTM is able to solve undecidable problems. His suggested FTM structure,
      which highly resembles the original definition was one of the most well-known
      classical definitions of FTM this http URL improve some of its weaknesses and
      vague points which will be discussed extensively in this paper, we will develop
      a more complete definition for fuzzy Turing machines. Our proposed definition
      of FTM, which encompasses the conventional definition, is motivated from the
      definition of General Fuzzy Automata (GFA) introduced by Doostfatemeh and Kremer.
      As it improved the conventional definition of fuzzy automata, especially the
      problem of membership assignment and multi-membership resolution, we also improved
      the same aspects of FTM through the definition of Comprehensive Fuzzy Turing
      Machine (CFTM). In addition, we address on some possible vaguenesses in FTM
      was not the subject of focus in fuzzy automata. As example, we investigate the
      issue of multi-path and multi-direction which are possible in case of nondeterminism.
      Finally, we show the simplicity, applicability and computational efficiency
      of the CFTM through an explanatory example.", "venue": "arXiv.org", "year":
      2019, "referenceCount": 12, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Engineering"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Engineering", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-08-06", "journal": {"name": "ArXiv", "volume": "abs/1908.01994"},
      "authors": [{"authorId": "103473852", "name": "N. Ahang"}, {"authorId": "34654901",
      "name": "A. Torabi"}, {"authorId": "2083881", "name": "M. Doostfatemeh"}]},
      {"paperId": "9c90c0fa5d247066c81fffc8bf01dcde2d7f7086", "externalIds": {"DBLP":
      "journals/corr/abs-1902-07245", "MAG": "2918081331", "CorpusId": 67770964},
      "corpusId": 67770964, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/9c90c0fa5d247066c81fffc8bf01dcde2d7f7086",
      "title": "Continuous Ordinary Differential Equations and Infinite Time Turing
      Machines", "abstract": "We consider Continuous Ordinary Differential Equations
      (CODE) y''=f(y), where f is a continuous function. They are known to always
      have solutions for a given initial condition y(0)=y0, these solutions being
      possibly non unique. We restrict to our attention to a class of continuous functions,
      that we call greedy: they always admit unique greedy solutions, i.e. going in
      greedy way in some fixed direction. \nWe prove that they can be seen as models
      of computation over the ordinals (Infinite Time Turing Machines, ITTM) and conversely
      in a very strong sense. \nIn particular, for such ODEs, to a greedy trajectory
      can be associated some ordinal corresponding to some time of computation, and
      conversely models of computation over the ordinals can be associated to some
      CODE. In particular, analyzing reachability for one or the other concept with
      respect to greedy trajectories has the same hardness. This also brings new perspectives
      on analysis in Mathematics, by providing ways to translate results for ITTMs
      to CODEs. This also extends some recent results about the relations between
      ordinary differential equations and Turing machines, and more widely with (generalized)
      computability theory.", "venue": "arXiv.org", "year": 2019, "referenceCount":
      30, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Mathematics",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-02-19", "journal":
      {"name": "ArXiv", "volume": "abs/1902.07245"}, "authors": [{"authorId": "1706341",
      "name": "Olivier Bournez"}, {"authorId": "11263956", "name": "S. Ouazzani"}]},
      {"paperId": "42db3debe939a2f323f91107ee22845f2d423753", "externalIds": {"DBLP":
      "journals/corr/abs-1902-07115", "MAG": "2917031985", "ArXiv": "1902.07115",
      "CorpusId": 67749912}, "corpusId": 67749912, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/42db3debe939a2f323f91107ee22845f2d423753",
      "title": "An entropic feature selection method in perspective of Turing formula",
      "abstract": "Health data are generally complex in type and small in sample size.
      Such domain-specific challenges make it difficult to capture information reliably
      and contribute further to the issue of generalization. To assist the analytics
      of healthcare datasets, we develop a feature selection method based on the concept
      of Coverage Adjusted Standardized Mutual Information (CASMI). The main advantages
      of the proposed method are: 1) it selects features more efficiently with the
      help of an improved entropy estimator, particularly when the sample size is
      small, and 2) it automatically learns the number of features to be selected
      based on the information from sample data. Additionally, the proposed method
      handles feature redundancy from the perspective of joint-distribution. The proposed
      method focuses on non-ordinal data, while it works with numerical data with
      an appropriate binning method. A simulation study comparing the proposed method
      to six widely cited feature selection methods shows that the proposed method
      performs better when measured by the Information Recovery Ratio, particularly
      when the sample size is small.", "venue": "arXiv.org", "year": 2019, "referenceCount":
      49, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-02-19", "journal": {"name": "ArXiv", "volume": "abs/1902.07115"}, "authors":
      [{"authorId": "1423498439", "name": "Jingyi Shi"}, {"authorId": "2108063443",
      "name": "Jialin Zhang"}, {"authorId": "37007400", "name": "Y. Ge"}]}, {"paperId":
      "c411c1861f4a6048dc1efd038624ba46a80f7b00", "externalIds": {"DBLP": "journals/corr/abs-1907-07767",
      "ArXiv": "1907.07767", "MAG": "2959626867", "CorpusId": 197544897}, "corpusId":
      197544897, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/c411c1861f4a6048dc1efd038624ba46a80f7b00",
      "title": "Delta - new logic programming language and Delta-methodology for p-computable
      programs on Turing Complete Languages", "abstract": "In paper describes the
      new logic programming language Delta, which have a many good properties. Delta-programs
      is p-computable, verifiable and can translation on other languages. Also we
      describe the Delta-methodology for constructing p-computable programs in high-level
      languages such as PHP, Java, JavaScript, C++, Pascal, Delphi, Python, Solidity
      and other. We would like to especially note the use of the Delta methodology
      for creating Smart Contracts and for Internet of things. We change the concept
      of the formula and define D-formulas(or Delta programs) are special list-formulas.
      Then we define the execution of a program how is the process of checking truth
      D-formula on a dynamic model. Main idea our paper consider program how list-formula
      from another formulas on dynamic models. And we created by iterations new Delta-programs
      use simple base formulas for this. Also we entered a dynamic models how models
      where we save final values of variables when check formula on this model.",
      "venue": "arXiv.org", "year": 2019, "referenceCount": 7, "citationCount": 1,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category":
      "Mathematics", "source": "external"}, {"category": "Computer Science", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-07-12", "journal": {"name": "ArXiv",
      "volume": "abs/1907.07767"}, "authors": [{"authorId": "87670088", "name": "A.
      Nechesov"}]}, {"paperId": "89f5af9fc5a8d79f89b53886f1ad18804696b70f", "externalIds":
      {"ArXiv": "1803.04548", "DBLP": "journals/corr/abs-1803-04548", "MAG": "2794062168",
      "CorpusId": 3834853}, "corpusId": 3834853, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/89f5af9fc5a8d79f89b53886f1ad18804696b70f",
      "title": "Taking Turing by Surprise? Designing Digital Computers for morally-loaded
      contexts", "abstract": "There is much to learn from what Turing hastily dismissed
      as Lady Lovelace s objection. Digital computers can indeed surprise us. Just
      like a piece of art, algorithms can be designed in such a way as to lead us
      to question our understanding of the world, or our place within it. Some humans
      do lose the capacity to be surprised in that way. It might be fear, or it might
      be the comfort of ideological certainties. As lazy normative animals, we do
      need to be able to rely on authorities to simplify our reasoning: that is ok.
      Yet the growing sophistication of systems designed to free us from the constraints
      of normative engagement may take us past a point of no-return. What if, through
      lack of normative exercise, our moral muscles became so atrophied as to leave
      us unable to question our social practices? This paper makes two distinct normative
      claims: \n1. Decision-support systems should be designed with a view to regularly
      jolting us out of our moral torpor. \n2. Without the depth of habit to somatically
      anchor model certainty, a computer s experience of something new is very different
      from that which in humans gives rise to non-trivial surprises. This asymmetry
      has key repercussions when it comes to the shape of ethical agency in artificial
      moral agents. The worry is not just that they would be likely to leap morally
      ahead of us, unencumbered by habits. The main reason to doubt that the moral
      trajectories of humans v. autonomous systems might remain compatible stems from
      the asymmetry in the mechanisms underlying moral change. Whereas in humans surprises
      will continue to play an important role in waking us to the need for moral change,
      cognitive processes will rule when it comes to machines. This asymmetry will
      translate into increasingly different moral outlooks, to the point of likely
      unintelligibility. The latter prospect is enough to doubt the desirability of
      autonomous moral agents.", "venue": "arXiv.org", "year": 2018, "referenceCount":
      44, "citationCount": 4, "influentialCitationCount": 1, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Art",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2018-03-12", "journal": {"name": "ArXiv", "volume": "abs/1803.04548"}, "authors":
      [{"authorId": "8288362", "name": "S. Delacroix"}]}, {"paperId": "45c182f8d003a2d505e4d1d491b5d03159a70b81",
      "externalIds": {"DBLP": "journals/corr/abs-1810-10948", "ArXiv": "1810.10948",
      "MAG": "2898148404", "CorpusId": 53032549}, "corpusId": 53032549, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/45c182f8d003a2d505e4d1d491b5d03159a70b81",
      "title": "Training Generative Adversarial Networks Via Turing Test", "abstract":
      "In this article, we introduce a new mode for training Generative Adversarial
      Networks (GANs). Rather than minimizing the distance of evidence distribution
      $\\tilde{p}(x)$ and the generative distribution $q(x)$, we minimize the distance
      of $\\tilde{p}(x_r)q(x_f)$ and $\\tilde{p}(x_f)q(x_r)$. This adversarial pattern
      can be interpreted as a Turing test in GANs. It allows us to use information
      of real samples during training generator and accelerates the whole training
      procedure. We even find that just proportionally increasing the size of discriminator
      and generator, it succeeds on 256x256 resolution without adjusting hyperparameters
      carefully.", "venue": "arXiv.org", "year": 2018, "referenceCount": 15, "citationCount":
      5, "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category":
      "Mathematics", "source": "external"}, {"category": "Computer Science", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2018-10-25", "journal": {"name": "ArXiv",
      "volume": "abs/1810.10948"}, "authors": [{"authorId": "51111230", "name": "Jianlin
      Su"}]}, {"paperId": "f963ad52f13e7edae84743e31381fff5b77bede5", "externalIds":
      {"ArXiv": "1711.08819", "MAG": "2768376195", "DBLP": "journals/corr/abs-1711-08819",
      "CorpusId": 583148}, "corpusId": 583148, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/f963ad52f13e7edae84743e31381fff5b77bede5",
      "title": "Improvised Comedy as a Turing Test", "abstract": "The best improvisational
      theatre actors can make any scene partner, of any skill level or ability, appear
      talented and proficient in the art form, and thus \"make them shine\". To challenge
      this improvisational paradigm, we built an artificial intelligence (AI) trained
      to perform live shows alongside human actors for human audiences. Over the course
      of 30 performances to a combined audience of almost 3000 people, we have refined
      theatrical games which involve combinations of human and (at times, adversarial)
      AI actors. We have developed specific scene structures to include audience participants
      in interesting ways. Finally, we developed a complete show structure that submitted
      the audience to a Turing test and observed their suspension of disbelief, which
      we believe is key for human/non-human theatre co-creation.", "venue": "arXiv.org",
      "year": 2017, "referenceCount": 10, "citationCount": 13, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Psychology", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2017-11-23", "journal": {"name": "ArXiv", "volume": "abs/1711.08819"},
      "authors": [{"authorId": "3422828", "name": "K. Mathewson"}, {"authorId": "144705062",
      "name": "Piotr Wojciech Mirowski"}]}, {"paperId": "c4a343d017569129c57e0f3dbb383d56cbf85707",
      "externalIds": {"DBLP": "journals/corr/abs-1904-09163", "MAG": "2939115675",
      "ArXiv": "1904.09163", "CorpusId": 126166939}, "corpusId": 126166939, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/c4a343d017569129c57e0f3dbb383d56cbf85707",
      "title": "Transfer Entropy: where Shannon meets Turing", "abstract": "Transfer
      entropy is capable of capturing nonlinear source-destination relations between
      multi-variate time series. It is a measure of association between source data
      that are transformed into destination data via a set of linear transformations
      between their probability mass functions. The resulting tensor formalism is
      used to show that in specific cases, e.g., in the case the system consists of
      three stochastic processes, bivariate analysis suffices to distinguish true
      relations from false relations. This allows us to determine the causal structure
      as far as encoded in the probability mass functions of noisy data. The tensor
      formalism was also used to derive the Data Processing Inequality for transfer
      entropy.", "venue": "arXiv.org", "year": 2019, "referenceCount": 13, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-04-19", "journal": {"name": "ArXiv",
      "volume": "abs/1904.09163"}, "authors": [{"authorId": "104300595", "name": "David
      Sigtermans"}]}, {"paperId": "3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9", "externalIds":
      {"MAG": "300525892", "DBLP": "journals/corr/MalinowskiF14a", "ArXiv": "1410.8027",
      "CorpusId": 811868}, "corpusId": 811868, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9",
      "title": "Towards a Visual Turing Challenge", "abstract": "As language and visual
      understanding by machines progresses rapidly, we are observing an increasing
      interest in holistic architectures that tightly interlink both modalities in
      a joint learning and inference process. This trend has allowed the community
      to progress towards more challenging and open tasks and refueled the hope at
      achieving the old AI dream of building machines that could pass a turing test
      in open domains. In order to steadily make progress towards this goal, we realize
      that quantifying performance becomes increasingly difficult. Therefore we ask
      how we can precisely define such challenges and how we can evaluate different
      algorithms on this open tasks? In this paper, we summarize and discuss such
      challenges as well as try to give answers where appropriate options are available
      in the literature. We exemplify some of the solutions on a recently presented
      dataset of question-answering task based on real-world indoor images that establishes
      a visual turing challenge. Finally, we argue despite the success of unique ground-truth
      annotation, we likely have to step away from carefully curated dataset and rather
      rely on ''social consensus'' as the main driving force to create suitable benchmarks.
      Providing coverage in this inherently ambiguous output space is an emerging
      challenge that we face in order to make quantifiable progress in this area.",
      "venue": "arXiv.org", "year": 2014, "referenceCount": 64, "citationCount": 69,
      "influentialCitationCount": 11, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2014-10-29", "journal": {"name": "ArXiv", "volume": "abs/1410.8027"}, "authors":
      [{"authorId": "145478807", "name": "Mateusz Malinowski"}, {"authorId": "1739548",
      "name": "Mario Fritz"}]}, {"paperId": "f19795ca9798adbf1ee6928add55e8c2438f8a32",
      "externalIds": {"MAG": "2795355335", "DBLP": "journals/corr/abs-1803-10648",
      "ArXiv": "1803.10648", "CorpusId": 4392393}, "corpusId": 4392393, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/f19795ca9798adbf1ee6928add55e8c2438f8a32",
      "title": "A Distributed Extension of the Turing Machine", "abstract": "The Turing
      Machine has two implicit properties that depend on its underlying notion of
      computing: the format is fully determinate and computations are information
      preserving. Distributed representations lack these properties and cannot be
      fully captured by Turing''s standard model. To address this limitation a distributed
      extension of the Turing Machine is introduced in this paper. In the extended
      machine, functions and abstractions are expressed extensionally and computations
      are entropic. The machine is applied to the definition of an associative memory,
      with its corresponding memory register, recognition and retrieval operations.
      The memory is tested with an experiment for storing and recognizing hand written
      digits with satisfactory results. The experiment can be seen as a proof of concept
      that information can be stored and processed effectively in a highly distributed
      fashion using a symbolic but not fully determinate format. The new machine augments
      the symbolic mode of computing with consequences on the way Church Thesis is
      understood. The paper is concluded with a discussion of some implications of
      the extended machine for Artificial Intelligence and Cognition.", "venue": "arXiv.org",
      "year": 2018, "referenceCount": 49, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2018-03-28", "journal": {"name": "ArXiv",
      "volume": "abs/1803.10648"}, "authors": [{"authorId": "144014054", "name": "L.
      Pineda"}]}, {"paperId": "4a4b5c8511f7a2a26f5847437d9fcdcf4a72c0f4", "externalIds":
      {"MAG": "2953095626", "DBLP": "journals/corr/abs-1710-04748", "ArXiv": "1710.04748",
      "CorpusId": 3784100}, "corpusId": 3784100, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/4a4b5c8511f7a2a26f5847437d9fcdcf4a72c0f4",
      "title": "HyperENTM: Evolving Scalable Neural Turing Machines through HyperNEAT",
      "abstract": "Recent developments within memory-augmented neural networks have
      solved sequential problems requiring long-term memory, which are intractable
      for traditional neural networks. However, current approaches still struggle
      to scale to large memory sizes and sequence lengths. In this paper we show how
      access to memory can be encoded geometrically through a HyperNEAT-based Neural
      Turing Machine (HyperENTM). We demonstrate that using the indirect HyperNEAT
      encoding allows for training on small memory vectors in a bit-vector copy task
      and then applying the knowledge gained from such training to speed up training
      on larger size memory vectors. Additionally, we demonstrate that in some instances,
      networks trained to copy bit-vectors of size 9 can be scaled to sizes of 1,000
      without further training. While the task in this paper is simple, these results
      could open up the problems amendable to networks with external memories to problems
      with larger memory vectors and theoretically unbounded memory sizes.", "venue":
      "arXiv.org", "year": 2017, "referenceCount": 23, "citationCount": 9, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2017-10-12", "journal": {"name": "ArXiv",
      "volume": "abs/1710.04748"}, "authors": [{"authorId": "27635664", "name": "Jakob
      Merrild"}, {"authorId": "2066553523", "name": "Mikkel Angaju Rasmussen"}, {"authorId":
      "1745664", "name": "S. Risi"}]}, {"paperId": "c86d6f344e4cf62af216bea8d51ad500bf9edfd4",
      "externalIds": {"DBLP": "journals/corr/Yang16", "MAG": "2952984004", "ArXiv":
      "1602.08671", "CorpusId": 9152132}, "corpusId": 9152132, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/c86d6f344e4cf62af216bea8d51ad500bf9edfd4",
      "title": "Lie Access Neural Turing Machine", "abstract": "Following the recent
      trend in explicit neural memory structures, we present a new design of an external
      memory, wherein memories are stored in an Euclidean key space $\\mathbb R^n$.
      An LSTM controller performs read and write via specialized read and write heads.
      It can move a head by either providing a new address in the key space (aka random
      access) or moving from its previous position via a Lie group action (aka Lie
      access). In this way, the \"L\" and \"R\" instructions of a traditional Turing
      Machine are generalized to arbitrary elements of a fixed Lie group action. For
      this reason, we name this new model the Lie Access Neural Turing Machine, or
      LANTM. \nWe tested two different configurations of LANTM against an LSTM baseline
      in several basic experiments. We found the right configuration of LANTM to outperform
      the baseline in all of our experiments. In particular, we trained LANTM on addition
      of $k$-digit numbers for $2 \\le k \\le 16$, but it was able to generalize almost
      perfectly to $17 \\le k \\le 32$, all with the number of parameters 2 orders
      of magnitude below the LSTM baseline.", "venue": "arXiv.org", "year": 2016,
      "referenceCount": 35, "citationCount": 15, "influentialCitationCount": 1, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2016-02-28", "journal": {"name": "ArXiv", "volume": "abs/1602.08671"},
      "authors": [{"authorId": "35064203", "name": "Greg Yang"}]}, {"paperId": "b71ee76a1fd357aeacad7768aa9c8528d2611783",
      "externalIds": {"DBLP": "journals/corr/abs-1802-05734", "MAG": "2788996312",
      "CorpusId": 59158844}, "corpusId": 59158844, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/b71ee76a1fd357aeacad7768aa9c8528d2611783",
      "title": "Writability and reachability for alpha-tape infinite time Turing machines",
      "abstract": "Infinite time Turing machines with tape length $\\alpha$ (denoted
      $T_\\alpha$) were introduced by Rin to strengthen the $\\omega$-tape machines
      of Hamkins and Kidder. It is known that for some countable ordinals $\\alpha$,
      these machines'' properties are quite different from those of the $\\omega$-tape
      case. We answer a question of Rin about the size of the least ordinal $\\delta$
      such that not all cells are halting positions of $T_\\delta$ by giving various
      characterizations of $\\delta$. For instance, it is the least ordinal with any
      of the properties (a) there is a $T_\\alpha$-writable real that is not $T_\\delta$-writable
      for some $\\alpha<\\delta$, (b) $\\delta$ is uncountable in $L_{\\lambda_\\delta}$,
      or (c) $\\delta$ is a regular cardinal in $L_{\\lambda_\\delta}$, where $\\lambda_\\delta$
      denotes the supremum of ordinals with a $T_\\delta$-writable code of length
      $\\delta$. We further use these characterizations together with an analogue
      to Welch''s submodel characterization of the ordinals $\\lambda$, $\\zeta$ and
      $\\Sigma$, to show that $\\delta$ is closed under the function $\\alpha \\mapsto
      \\Sigma_\\alpha$, where $\\Sigma_\\alpha$ denotes the supremum of the ordinals
      with a $T_\\alpha$-accidentally writable code of length $\\alpha$.", "venue":
      "arXiv.org", "year": 2018, "referenceCount": 10, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category":
      "Mathematics", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2018-02-15", "journal": {"name": "ArXiv", "volume": "abs/1802.05734"},
      "authors": [{"authorId": "2618125", "name": "M. Carl"}, {"authorId": "1838366",
      "name": "Benjamin G. Rin"}, {"authorId": "2268646", "name": "Philipp Schlicht"}]},
      {"paperId": "6d4553d571939763e585b2dfbf8129b2d3f38c44", "externalIds": {"ArXiv":
      "1807.02287", "DBLP": "journals/corr/abs-1807-02287", "MAG": "2814812544", "CorpusId":
      49654281}, "corpusId": 49654281, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/6d4553d571939763e585b2dfbf8129b2d3f38c44",
      "title": "Outperforming Good-Turing: Preliminary Report", "abstract": "Estimating
      a large alphabet probability distribution from a limited number of samples is
      a fundamental problem in machine learning and statistics. A variety of estimation
      schemes have been proposed over the years, mostly inspired by the early work
      of Laplace and the seminal contribution of Good and Turing. One of the basic
      assumptions shared by most commonly-used estimators is the unique correspondence
      between the symbol''s sample frequency and its estimated probability. In this
      work we tackle this paradigmatic assumption; we claim that symbols with \"similar\"
      frequencies shall be assigned the same estimated probability value. This way
      we regulate the number of parameters and improve generalization. In this preliminary
      report we show that by applying an ensemble of such regulated estimators, we
      introduce a dramatic enhancement in the estimation accuracy (typically up to
      50%), compared to currently known methods. An implementation of our suggested
      method is publicly available at the first author''s web-page.", "venue": "arXiv.org",
      "year": 2018, "referenceCount": 13, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2018-07-06", "journal": {"name": "ArXiv", "volume": "abs/1807.02287"},
      "authors": [{"authorId": "3092268", "name": "Amichai Painsky"}, {"authorId":
      "144519810", "name": "M. Feder"}]}, {"paperId": "1487e19ad896ef85a7032bc2e8d870ae123f6c96",
      "externalIds": {"DBLP": "journals/corr/KleinR17", "ArXiv": "1706.06845", "MAG":
      "2683402793", "CorpusId": 29951564}, "corpusId": 29951564, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/1487e19ad896ef85a7032bc2e8d870ae123f6c96",
      "title": "Turing Completeness of Finite, Epistemic Programs", "abstract": "In
      this note, we show the class of finite, epistemic programs to be Turing complete.
      Epistemic programs is a widely used update mechanism used in epistemic logic,
      where it such are a special type of action models: One which does not contain
      postconditions.", "venue": "arXiv.org", "year": 2017, "referenceCount": 8, "citationCount":
      3, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Philosophy", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2017-06-21", "journal": {"name": "ArXiv",
      "volume": "abs/1706.06845"}, "authors": [{"authorId": "145564526", "name": "Dominik
      Klein"}, {"authorId": "2333821", "name": "R. K. Rendsvig"}]}, {"paperId": "55e1782af4b596a06a5e2bd1bc5ec721722042f7",
      "externalIds": {"MAG": "2592218156", "DBLP": "journals/corr/Raptis17", "ArXiv":
      "1702.06000", "DOI": "10.1016/j.chaos.2017.09.033", "CorpusId": 10117033}, "corpusId":
      10117033, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/55e1782af4b596a06a5e2bd1bc5ec721722042f7",
      "title": "''Viral'' Turing Machines, Computation from Noise and Combinatorial
      Hierarchies", "abstract": null, "venue": "arXiv.org", "year": 2017, "referenceCount":
      65, "citationCount": 8, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "https://arxiv.org/pdf/1702.06000", "status": "GREEN"},
      "fieldsOfStudy": ["Computer Science", "Physics", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Physics",
      "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
      "Review"], "publicationDate": "2017-01-31", "journal": {"name": "ArXiv", "volume":
      "abs/1702.06000"}, "authors": [{"authorId": "144656250", "name": "T. Raptis"}]},
      {"paperId": "8c38a6a14fe4d90efe815d895cd58b6674737a3c", "externalIds": {"ArXiv":
      "1612.00827", "DBLP": "journals/corr/DeleuD16", "MAG": "2560826841", "CorpusId":
      1033884}, "corpusId": 1033884, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "http://bibpurl.oclc.org/web/7130"}, "url": "https://www.semanticscholar.org/paper/8c38a6a14fe4d90efe815d895cd58b6674737a3c",
      "title": "Learning Operations on a Stack with Neural Turing Machines", "abstract":
      "Multiple extensions of Recurrent Neural Networks (RNNs) have been proposed
      recently to address the difficulty of storing information over long time periods.
      In this paper, we experiment with the capacity of Neural Turing Machines (NTMs)
      to deal with these long-term dependencies on well-balanced strings of parentheses.
      We show that not only does the NTM emulate a stack with its heads and learn
      an algorithm to recognize such words, but it is also capable of strongly generalizing
      to much longer sequences.", "venue": "arXiv.org", "year": 2016, "referenceCount":
      20, "citationCount": 8, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2016-12-02", "journal": {"name": "ArXiv", "volume": "abs/1612.00827"},
      "authors": [{"authorId": "7636193", "name": "T. Deleu"}, {"authorId": "7432502",
      "name": "J. Dureau"}]}, {"paperId": "f01345a2efc1aa5100b27caf82368bf410937152",
      "externalIds": {"ArXiv": "1510.03931", "DBLP": "journals/corr/ZhangYZ15", "MAG":
      "2211729040", "CorpusId": 15463561}, "corpusId": 15463561, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/f01345a2efc1aa5100b27caf82368bf410937152",
      "title": "Structured Memory for Neural Turing Machines", "abstract": "Neural
      Turing Machines (NTM) contain memory component that simulates \"working memory\"
      in the brain to store and retrieve information to ease simple algorithms learning.
      So far, only linearly organized memory is proposed, and during experiments,
      we observed that the model does not always converge, and overfits easily when
      handling certain tasks. We think memory component is key to some faulty behaviors
      of NTM, and better organization of memory component could help fight those problems.
      In this paper, we propose several different structures of memory for NTM, and
      we proved in experiments that two of our proposed structured-memory NTMs could
      lead to better convergence, in term of speed and prediction accuracy on copy
      task and associative recall task as in (Graves et al. 2014).", "venue": "arXiv.org",
      "year": 2015, "referenceCount": 5, "citationCount": 13, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2015-10-14", "journal": {"name": "ArXiv",
      "volume": "abs/1510.03931"}, "authors": [{"authorId": "47527881", "name": "Wei
      Zhang"}, {"authorId": "2152847920", "name": "Yang Yu"}, {"authorId": "145218984",
      "name": "Bowen Zhou"}]}, {"paperId": "d2b2cb1d5cc1aa30cf5be7bcb0494198934caabb",
      "externalIds": {"DBLP": "journals/corr/QiWLZ15", "MAG": "2193011350", "ArXiv":
      "1512.01715", "CorpusId": 14014490}, "corpusId": 14014490, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "http://bibpurl.oclc.org/web/7130"},
      "url": "https://www.semanticscholar.org/paper/d2b2cb1d5cc1aa30cf5be7bcb0494198934caabb",
      "title": "A Restricted Visual Turing Test for Deep Scene and Event Understanding",
      "abstract": "This paper presents a restricted visual Turing test (VTT) for story-line
      based deep understanding in long-term and multi-camera captured videos. Given
      a set of videos of a scene (such as a multi-room office, a garden, and a parking
      lot.) and a sequence of story-line based queries, the task is to provide answers
      either simply in binary form \"true/false\" (to a polar query) or in an accurate
      natural language description (to a non-polar query). Queries, polar or non-polar,
      consist of view-based queries which can be answered from a particular camera
      view and scene-centered queries which involves joint inference across different
      cameras. The story lines are collected to cover spatial, temporal and causal
      understanding of input videos. The data and queries distinguish our VTT from
      recently proposed visual question answering in images and video captioning.
      A vision system is proposed to perform joint video and query parsing which integrates
      different vision modules, a knowledge base and a query engine. The system provides
      unified interfaces for different modules so that individual modules can be reconfigured
      to test a new method. We provide a benchmark dataset and a toolkit for ontology
      guided story-line query generation which consists of about 93.5 hours videos
      captured in four different locations and 3,426 queries split into 127 story
      lines. We also provide a baseline implementation and result analyses.", "venue":
      "arXiv.org", "year": 2015, "referenceCount": 46, "citationCount": 12, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2015-12-06", "journal": {"name": "ArXiv",
      "volume": "abs/1512.01715"}, "authors": [{"authorId": "47935745", "name": "Qi"},
      {"authorId": "47353858", "name": "Tianfu Wu"}, {"authorId": "2649483", "name":
      "M. Lee"}, {"authorId": "145380991", "name": "Song-Chun Zhu"}]}]}

      '
    headers:
      Access-Control-Allow-Origin:
      - '*'
      Connection:
      - keep-alive
      Content-Length:
      - '217760'
      Content-Type:
      - application/json
      Date:
      - Thu, 07 Sep 2023 20:26:55 GMT
      Via:
      - 1.1 ea450411fc852f7d373f7efbe784dd74.cloudfront.net (CloudFront)
      X-Amz-Cf-Id:
      - m3z-m4tFJgkZhXp2ZaVaQcgwwVn8XuPlVhky1lToFzR0Kex0UxkeDQ==
      X-Amz-Cf-Pop:
      - EWR50-C1
      X-Cache:
      - Miss from cloudfront
      x-amz-apigw-id:
      - K5zCRFE-PHcF4ZA=
      x-amzn-Remapped-Connection:
      - keep-alive
      x-amzn-Remapped-Content-Length:
      - '217760'
      x-amzn-Remapped-Date:
      - Thu, 07 Sep 2023 20:26:55 GMT
      x-amzn-Remapped-Server:
      - gunicorn
      x-amzn-RequestId:
      - 591baf2b-bd4a-489f-a1b3-4733d067157e
    http_version: HTTP/1.1
    status_code: 200
version: 1
